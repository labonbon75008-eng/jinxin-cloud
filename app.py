import streamlit as st
import os
import json
import time
import uuid
import re
import io
import asyncio
import base64
import requests
import pandas as pd
import warnings
import contextlib
import matplotlib
# 1. å¼ºåˆ¶åå°ç»˜å›¾
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import yfinance as yf
from docx import Document
from datetime import datetime

# ã€é˜²å´©å¯¼å…¥ã€‘è¯­éŸ³ç»„ä»¶
try:
    from streamlit_mic_recorder import mic_recorder
except ImportError:
    mic_recorder = None

import edge_tts
import speech_recognition as sr
import google.generativeai as genai
from PIL import Image

# ================= 1. ç³»ç»Ÿé…ç½® =================
warnings.filterwarnings("ignore")
st.set_page_config(page_title="é‡‘é‘« - æŠ•èµ„åŠ©ç†", page_icon="ğŸ‘©â€ğŸ’¼", layout="wide")

# CSS: å¼ºåˆ¶æ‰‹æœºæŒ‰é’®ä¸æ¢è¡Œ + å¤´åƒä¼˜åŒ–
st.markdown("""
<style>
    div[data-testid="stHorizontalBlock"] { flex-wrap: nowrap !important; overflow-x: auto !important; }
    div[data-testid="stHorizontalBlock"] button { min-width: 60px !important; padding: 0px 5px !important; }
    .main-title { text-align: center; font-size: 26px; font-weight: bold; color: white; margin-bottom: 10px; }
    .avatar-img { 
        width: 120px; height: 120px; 
        border-radius: 50%; 
        border: 3px solid #4CAF50; 
        margin: 0 auto; display: block; 
        object-fit: cover; background-color: #eee;
    }
    button[title="View fullscreen"] { display: none; }
</style>
""", unsafe_allow_html=True)

# æ ¸å¿ƒè·¯å¾„
MEMORY_FILE = "investment_memory_v24.json"
CHARTS_DIR = "charts"
AUDIO_DIR = "audio_cache"
FONT_PATH = "SimHei.ttf" 

for d in [CHARTS_DIR, AUDIO_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# API KEY
try:
    if "GEMINI_API_KEY" in st.secrets:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    else:
        genai.configure(api_key="AIzaSyAaN5lJUzp7MXQuLyi8NMV5V26aizR8kBU")
except: pass

# ================= 2. èµ„æºç®¡ç† =================

def load_font():
    if not os.path.exists(FONT_PATH):
        try:
            r = requests.get("https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf", timeout=5)
            with open(FONT_PATH, "wb") as f: f.write(r.content)
        except: pass
    try:
        if os.path.exists(FONT_PATH):
            fm.fontManager.addfont(FONT_PATH)
            plt.rcParams['font.sans-serif'] = ['SimHei']
            plt.rcParams['axes.unicode_minus'] = False
    except: pass

load_font()

DEFAULT_AVATAR = "https://api.dicebear.com/9.x/avataaars/png?seed=Jinxin&clothing=blazerAndShirt&hairColor=black&skinColor=light&accessories=glasses&top=longHairStraight"

def get_avatar():
    if os.path.exists("avatar.png"): return "avatar.png"
    return DEFAULT_AVATAR

# ================= 3. æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ =================

# --- A. æ•°æ®å¼•æ“ ---
def get_stock_data(query):
    s = str(query).strip().upper()
    match = re.search(r"[0-9]{4,6}", s)
    code = match.group() if match else "000001"
    
    info_str = "æš‚æ— æ•°æ®"; curr = 0.0
    
    # 1. Sina
    try:
        sina_code = f"sh{code}" if code.startswith('6') else f"sz{code}"
        if len(code) == 5: sina_code = f"hk{code}"
        
        url = f"http://hq.sinajs.cn/list={sina_code}"
        r = requests.get(url, headers={'Referer':'https://finance.sina.com.cn'}, timeout=2)
        if len(r.text) > 20:
            parts = r.text.split('"')[1].split(',')
            name = parts[0]
            if len(parts) > 3:
                if "hk" in sina_code: curr = float(parts[6])
                else: curr = float(parts[3])
                info_str = f"ã€{name}ã€‘ ç°ä»·: {curr}"
    except: pass

    # 2. Yahoo
    df = None
    try:
        ticker = f"{code}.SS" if code.startswith('6') else (f"{code}.HK" if len(code)==5 else f"{code}.SZ")
        df = yf.Ticker(ticker).history(period="1mo")
        if df.empty:
            idx = pd.date_range(end=datetime.now(), periods=5)
            df = pd.DataFrame({'Close': [curr if curr>0 else 100]*5}, index=idx)
    except: 
        idx = pd.date_range(end=datetime.now(), periods=5)
        df = pd.DataFrame({'Close': [100]*5}, index=idx)

    return df, info_str

# --- B. ä»£ç æ‰§è¡Œ ---
def execute_code(code_str):
    img_path = None
    capture = io.StringIO()
    code = code_str.replace("plt.show()", "")
    lines = [l for l in code.split('\n') if not l.strip().startswith(('import', 'from'))]
    safe_code = '\n'.join(lines)
    
    try:
        plt.close('all'); plt.clf(); plt.figure(figsize=(8, 4))
        local_vars = {
            'get_stock_data': get_stock_data,
            'plt': plt, 'pd': pd, 'yf': yf, 
            'datetime': datetime, 'contextlib': contextlib
        }
        with contextlib.redirect_stdout(capture):
            exec(safe_code, globals(), local_vars)
        
        if plt.get_fignums():
            fname = f"chart_{int(time.time())}.png"
            img_path = os.path.join(CHARTS_DIR, fname)
            plt.savefig(img_path, bbox_inches='tight', dpi=100); plt.close()
    except: pass
    
    return img_path

# --- C. AI æ€è€ƒ ---
def get_ai_response(user_text):
    try:
        model = genai.GenerativeModel("gemini-3-pro-preview")
        _, real_info = get_stock_data(user_text)
        
        prompt = f"""
        ä½ å«é‡‘é‘«ï¼ŒæŠ•èµ„é¡¾é—®ã€‚å½“å‰æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d')}ã€‚
        ç”¨æˆ·é—®ï¼š{user_text}
        **å‚è€ƒæ•°æ®**ï¼š{real_info}
        
        è¦æ±‚ï¼š
        1. åŸºäºæ•°æ®å›ç­”ã€‚
        2. ç”Ÿæˆ Python ä»£ç ç”»å›¾ (ä½¿ç”¨ df, info = get_stock_data("ä»£ç "))ã€‚
        3. å›ç­”ç®€ç»ƒï¼ŒåƒçœŸäººã€‚
        """
        resp = model.generate_content(prompt)
        return resp.text
    except Exception as e:
        return f"ç³»ç»Ÿç¹å¿™: {e}"

# --- D. è¯­éŸ³/æ–‡æœ¬å¤„ç† ---
def transcribe(audio_bytes):
    if not audio_bytes: return None
    r = sr.Recognizer()
    try:
        with sr.AudioFile(io.BytesIO(audio_bytes)) as source:
            return r.recognize_google(r.record(source), language='zh-CN')
    except: return None

def clean_text_display(text):
    return re.sub(r'```.*?```', '', text, flags=re.DOTALL).strip()

async def gen_voice(text, path):
    try: await edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural").save(path); return True
    except: return False

# --- E. è®°å¿† ---
def load_mem():
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r") as f: return json.load(f)
        except: pass
    return []

def save_mem(msgs):
    clean_msgs = []
    for m in msgs:
        temp = m.copy()
        if "chart_buf" in temp: del temp["chart_buf"]
        clean_msgs.append(temp)
    with open(MEMORY_FILE, "w") as f: json.dump(clean_msgs, f)

def create_doc(msgs, idx=None):
    doc = Document(); doc.add_heading("é‡‘é‘«ç ”æŠ¥", 0)
    targets = [msgs[idx]] if idx is not None else msgs
    for m in targets:
        if not m.get("hidden"):
            doc.add_heading(f"{m['role']}", 2); doc.add_paragraph(clean_text_display(m.get("content","")))
    b = io.BytesIO(); doc.save(b); b.seek(0); return b

# ================= 4. ç•Œé¢å¸ƒå±€ =================

if "messages" not in st.session_state: st.session_state.messages = load_mem()
if "last_audio" not in st.session_state: st.session_state.last_audio = None
if "monitor" not in st.session_state: st.session_state.monitor = False

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.image(get_avatar(), width=100)
    st.markdown("<h3 style='text-align:center'>é‡‘é‘«</h3>", unsafe_allow_html=True)
    
    with st.expander("ğŸ¯ ç›¯ç›˜", expanded=True):
        m_code = st.text_input("ä»£ç ", "300750")
        m_tgt = st.number_input("ç›®æ ‡", 0.0)
        if st.button("ğŸ”´ å¯åŠ¨/åœæ­¢"):
            st.session_state.monitor = not st.session_state.monitor
            st.rerun()
        if st.session_state.monitor:
            st.info("ğŸ“¡ ç›‘æ§ä¸­...")
            df, info = get_stock_data(m_code)
            if "ç°ä»·" in str(info):
                try:
                    curr = float(re.search(r"ç°ä»·: (\d+\.\d+)", str(info)).group(1))
                    st.metric("å®æ—¶ä»·", curr)
                    if curr < m_tgt: st.error("è§¦å‘ç›®æ ‡ä»·ï¼"); st.session_state.monitor = False
                except: pass

    st.divider()
    search = st.text_input("ğŸ” æœç´¢")
    
    c1, c2 = st.columns(2)
    if c1.button("ğŸ—‘ï¸ æ¸…ç©º", use_container_width=True):
        st.session_state.messages = []
        if os.path.exists(MEMORY_FILE): os.remove(MEMORY_FILE)
        st.rerun()
    c2.download_button("ğŸ“¥ å¯¼å‡º", create_doc(st.session_state.messages), "all.docx", use_container_width=True)

# --- ä¸»ç•Œé¢ ---
st.markdown("<div class='main-title'>æ‚¨çš„å…¨å¤©å€™æŠ•èµ„åŠ©ç†</div>", unsafe_allow_html=True)
st.markdown(f"<img src='{get_avatar()}' class='avatar-img'>", unsafe_allow_html=True)

# 1. æ¸²æŸ“æ¶ˆæ¯
for i, msg in enumerate(st.session_state.messages):
    role = msg["role"]
    av = get_avatar() if role == "assistant" else "ğŸ‘¨â€ğŸ’¼"
    
    if msg.get("hidden"): continue
    
    with st.chat_message(role, avatar=av):
        clean_txt = clean_text_display(msg["content"])
        st.write(clean_txt)
        
        if msg.get("image_path") and os.path.exists(msg["image_path"]):
            st.image(msg["image_path"])
        
        if msg.get("audio_path") and os.path.exists(msg["audio_path"]):
            st.audio(msg["audio_path"])
            
        with st.expander("â‹® æ“ä½œ"):
            c1, c2, c3, c4 = st.columns([1,1,1,1])
            if c1.button("ğŸ“‹", key=f"cp_{i}", help="å¤åˆ¶"): st.code(clean_txt)
            if c2.button("ğŸ™ˆ", key=f"hd_{i}", help="éšè—"): 
                st.session_state.messages[i]["hidden"] = True; save_mem(st.session_state.messages); st.rerun()
            if c3.button("ğŸ—‘ï¸", key=f"dl_{i}", help="åˆ é™¤"): 
                del st.session_state.messages[i]; save_mem(st.session_state.messages); st.rerun()
            c4.download_button("ğŸ“¥", create_doc(st.session_state.messages, i), f"msg_{i}.docx", key=f"ex_{i}", help="å¯¼å‡º")

# 2. è¾“å…¥å¤„ç† (æ”¾åœ¨å¤–å±‚ï¼Œç¡®ä¿æ°¸è¿œæ˜¾ç¤º)
st.markdown("---")
c_voice, c_text = st.columns([1, 5])

# è¯­éŸ³ç»„ä»¶ (é˜²å´©)
user_input = None
if mic_recorder:
    with c_voice:
        try:
            audio = mic_recorder(start_prompt="ğŸ™ï¸", stop_prompt="â¹ï¸", key='mic')
            if audio and audio['bytes']:
                if "last_audio_bytes" not in st.session_state or st.session_state.last_audio_bytes != audio['bytes']:
                    st.session_state.last_audio_bytes = audio['bytes']
                    with st.spinner("è¯†åˆ«ä¸­..."):
                        voice_text = transcribe(audio['bytes'])
                        if voice_text: user_input = voice_text
                        else: st.warning("æœªæ£€æµ‹åˆ°è¯­éŸ³")
        except: 
            st.caption("è¯­éŸ³ä¸å¯ç”¨")

# æ–‡å­—ç»„ä»¶
with c_text:
    text_input = st.chat_input("è¯·è¾“å…¥è‚¡ç¥¨ä»£ç æˆ–é—®é¢˜...")
    if text_input: user_input = text_input

# 3. å“åº”é€»è¾‘
if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input, "id": str(uuid.uuid4())})
    save_mem(st.session_state.messages)
    
    with st.chat_message("assistant", avatar=get_avatar()):
        with st.spinner("åˆ†æä¸­..."):
            full_response = get_ai_response(user_input)
            
            # æå–å¹¶æ‰§è¡Œä»£ç 
            img_p = None
            code_match = re.findall(r'```python(.*?)```', full_response, re.DOTALL)
            if code_match:
                img_p = execute_code(code_match[-1])
            
            # è¯­éŸ³ç”Ÿæˆ
            af = None
            clean_txt = clean_text_display(full_response)
            try:
                af = os.path.join(AUDIO_DIR, f"v_{int(time.time())}.mp3")
                asyncio.run(gen_voice(clean_txt[:300], af))
            except: pass
            
            st.markdown(clean_txt)
            if img_p: st.image(img_p)
            if af and os.path.exists(af): st.audio(af)
            
            st.session_state.messages.append({
                "role": "assistant",
                "content": full_response, 
                "image_path": img_p,
                "audio_path": af
            })
            save_mem(st.session_state.messages)
            
    st.rerun()

if st.session_state.monitor:
    time.sleep(5); st.rerun()
