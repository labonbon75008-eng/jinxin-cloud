import streamlit as st
import google.generativeai as genai
import os
import matplotlib
matplotlib.use('Agg') # ã€æ ¸å¿ƒä¿®å¤ã€‘å¼ºåˆ¶ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼Œé˜²æ­¢äº‘ç«¯ç”»å›¾å¡æ­»
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from docx import Document
from docx.shared import Inches
import re
import json
import time
import io
import uuid
import shutil
from datetime import datetime, timedelta
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
import asyncio
import edge_tts
import requests
import pandas as pd
import warnings
import contextlib
import sys
import yfinance as yf
from PIL import Image

# ================= 1. ç³»ç»Ÿæ ¸å¿ƒé…ç½® =================
warnings.filterwarnings("ignore")

st.set_page_config(page_title="é‡‘é‘« - æ™ºèƒ½è´¢å¯Œåˆä¼™äºº", page_icon="ğŸ‘©â€ğŸ’¼", layout="wide")

# è·¯å¾„åˆå§‹åŒ–
MEMORY_FILE = "investment_memory_cloud.json"
CHARTS_DIR = "charts"
AUDIO_DIR = "audio_cache"
for d in [CHARTS_DIR, AUDIO_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# API KEY
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    st.error("ğŸš¨ è¯·åœ¨ Streamlit Secrets ä¸­é…ç½® GEMINI_API_KEY")
    st.stop()

# ================= 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

def load_avatar(filename, default_emoji):
    extensions = ["png", "jpg", "jpeg", "PNG", "JPG"]
    base_name = filename.split('.')[0]
    for ext in extensions:
        path = f"{base_name}.{ext}"
        if os.path.exists(path): return path
    return None

def get_sina_code(symbol):
    s = symbol.strip().upper().replace(".SS", "").replace(".SZ", "").replace(".HK", "")
    if s.isdigit():
        if len(s) == 5: return f"hk{s}" 
        if len(s) == 4: return f"hk0{s}" 
        if len(s) == 6:
            if s.startswith('6'): return f"sh{s}"
            if s.startswith('0') or s.startswith('3'): return f"sz{s}"
            if s.startswith('8') or s.startswith('4'): return f"bj{s}"
    return f"sh{s}" if s.isdigit() else s

def get_stock_data_v8(ticker_symbol):
    """æé€Ÿæ•°æ®å¼•æ“"""
    sina_code = get_sina_code(ticker_symbol)
    info_str = "æš‚æ— å®æ—¶æ•°æ®"
    current_price = 0.0
    
    # 1. Sina Realtime
    try:
        url = f"http://hq.sinajs.cn/list={sina_code}"
        headers = {'Referer': 'https://finance.sina.com.cn'}
        r = requests.get(url, headers=headers, timeout=2, proxies={"http": None, "https": None})
        if '=""' not in r.text and len(r.text) > 20:
            parts = r.text.split('"')[1].split(',')
            name = parts[0]
            curr = float(parts[3])
            prev = float(parts[2])
            pct = ((curr - prev) / prev) * 100 if prev != 0 else 0
            date_time = datetime.now().strftime("%H:%M:%S")
            info_str = f"ã€{name}ã€‘ ç°ä»·: {curr:.2f} ({pct:+.2f}%) | æ—¶é—´: {date_time}"
            current_price = curr
    except Exception as e: print(f"Sina Error: {e}")

    # 2. Yahoo History (Chart)
    df = None
    try:
        y_sym = ticker_symbol.upper()
        if y_sym.isdigit():
            if y_sym.startswith('6'): y_sym += ".SS"
            elif y_sym.startswith('0'): y_sym += ".SZ"
            elif len(y_sym)==5: y_sym += ".HK"
        
        ticker = yf.Ticker(y_sym)
        # å°è¯•è·å–è¾ƒé•¿æ—¶é—´æ•°æ®ä»¥ä¿è¯ç”»å›¾ç¾è§‚
        hist = ticker.history(period="1mo") 
        if not hist.empty:
            df = hist[['Close']]
    except: pass

    # å…œåº•ï¼šå¦‚æœYahooæŒ‚äº†ä½†æ–°æµªæ´»ç€ï¼Œæ‰‹åŠ¨é€ ä¸€ä¸ªç‚¹é˜²æ­¢æŠ¥é”™
    if df is None and current_price > 0:
        df = pd.DataFrame({'Close': [current_price]}, index=[datetime.now()])

    return df, info_str

# --- è¯­éŸ³ä¸ AI ---
async def generate_audio_edge(text, output_file):
    try:
        communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
        await communicate.save(output_file)
        return True
    except: return False

def save_audio_cloud(text, output_path):
    try: asyncio.run(generate_audio_edge(text, output_path)); return True
    except: return False

def transcribe_audio(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_io = io.BytesIO(audio_bytes)
        with sr.AudioFile(audio_io) as source: audio_data = r.record(source)
        return r.recognize_google(audio_data, language='zh-CN')
    except: return None

def get_spoken_response(text_analysis):
    if not text_analysis: return ""
    try:
        model = genai.GenerativeModel("gemini-3-pro-preview")
        prompt = f"ä½ æ˜¯é‡‘é‘«ã€‚è¯·å°†æ­¤å†…å®¹è½¬ä¸º80å­—ä»¥å†…çš„å£è¯­ï¼Œä¸è¦å¿µæ•°æ®ï¼š\n{text_analysis}"
        response = model.generate_content(prompt)
        return response.text
    except: return ""

# --- æ¨¡å‹é…ç½® ---
def configure_chinese_font():
    font_candidates = [r"C:\Windows\Fonts\msyh.ttc", r"C:\Windows\Fonts\simhei.ttf"]
    for path in font_candidates:
        if os.path.exists(path):
            fm.fontManager.addfont(path)
            plt.rcParams['font.sans-serif'] = [fm.FontProperties(fname=path).get_name()]
            plt.rcParams['axes.unicode_minus'] = False
            break
configure_chinese_font()

current_time_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
SYSTEM_INSTRUCTION = f"""
ä½ å«â€œé‡‘é‘«â€ï¼Œç”¨æˆ·çš„ä¸“å±ç§äººè´¢å¯Œåˆä¼™äººã€‚å½“å‰æ—¥æœŸï¼š{current_time_str}ã€‚

ã€ä»»åŠ¡ã€‘
1. å¿…é¡»è°ƒç”¨ `get_stock_data_v8(ticker)` è·å–æ•°æ®ã€‚
2. Aè‚¡ä»£ç ç›´æ¥å†™æ•°å­— (å¦‚ 600309)ã€‚
3. å¿…é¡»åœ¨æœ€åç”»å›¾ã€‚

ã€ä»£ç æ¨¡æ¿ã€‘
ticker = "300750" 
df, info = get_stock_data_v8(ticker)

if df is not None:
    print(info) # æ‰“å°å®æ—¶ä¿¡æ¯
    plt.figure(figsize=(10, 5))
    plt.plot(df.index, df['Close'], label='Close', color='#c2185b') 
    plt.title(f"{{ticker}} Trend")
    plt.grid(True, alpha=0.3)
else:
    print(f"æ•°æ®ä¸å¯ç”¨: {{info}}")
"""

@st.cache_resource
def get_model():
    genai.configure(api_key=API_KEY)
    return genai.GenerativeModel(model_name="gemini-3-pro-preview", system_instruction=SYSTEM_INSTRUCTION)

# --- E. ä»£ç æ‰§è¡Œå¼•æ“ (æ ¸å¿ƒä¿®å¤ï¼šæ³¨å…¥ plt) ---
def execute_local_code_and_save(code_str):
    image_path = None; text_output = ""; output_capture = io.StringIO()
    try:
        plt.clf(); plt.figure(figsize=(10, 5), dpi=100) 
        
        # ã€å…³é”®ä¿®å¤ã€‘å…¨å±€æ³¨å…¥ plt, pd, yf, get_stock_data_v8
        # è¿™æ · AI å†™çš„ä»£ç é‡Œç›´æ¥ç”¨ plt.plot() å°±ä¸ä¼šæŠ¥é”™ "name 'plt' is not defined"
        local_vars = {
            'get_stock_data_v8': get_stock_data_v8,
            'plt': plt, 
            'pd': pd, 
            'yf': yf
        }
        
        with contextlib.redirect_stdout(output_capture):
            exec(code_str, globals(), local_vars)
            
        text_output = output_capture.getvalue()
        
        if plt.get_fignums():
            fig = plt.gcf()
            filename = f"chart_{int(time.time())}.png"
            image_path = os.path.join(CHARTS_DIR, filename)
            fig.savefig(image_path, format="png", bbox_inches='tight')
            plt.close(fig)
            
    except Exception as e: 
        text_output = f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
    
    return image_path, text_output

# --- F. è®°å¿†ç®¡ç† (æ ¸å¿ƒä¿®å¤ï¼šæ•°æ®æ¸…æ´—) ---
def load_memory():
    """è¯»å–å¹¶æ¸…æ´—è®°å¿†æ–‡ä»¶ï¼Œé˜²æ­¢ str æŠ¥é”™"""
    data = []
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r", encoding='utf-8') as f:
                raw_data = json.load(f)
                # ã€æ•°æ®æ¸…æ´—ã€‘åªä¿ç•™å­—å…¸ç±»å‹çš„æ•°æ®ï¼Œå‰”é™¤æŸåçš„å­—ç¬¦ä¸²
                if isinstance(raw_data, list):
                    for item in raw_data:
                        if isinstance(item, dict):
                            data.append(item)
        except: pass # å¦‚æœæ–‡ä»¶å½»åº•åäº†ï¼Œå°±è¿”å›ç©ºåˆ—è¡¨ï¼Œç›¸å½“äºé‡ç½®
    return data

def save_memory(messages):
    try:
        with open(MEMORY_FILE, "w", encoding='utf-8') as f: json.dump(messages, f, ensure_ascii=False, indent=2)
    except: pass

def delete_message(msg_id):
    for i, msg in enumerate(st.session_state.messages):
        if msg.get("id") == msg_id:
            del st.session_state.messages[i]; save_memory(st.session_state.messages); st.rerun(); break

def toggle_hidden(msg_id):
    for msg in st.session_state.messages:
        if msg.get("id") == msg_id:
            msg["hidden"] = not msg.get("hidden", False); save_memory(st.session_state.messages); st.rerun(); break

def create_word_doc(messages):
    doc = Document(); doc.add_heading("é‡‘é‘«è´¢å¯ŒæŠ¥å‘Š", 0)
    for msg in messages:
        if msg.get("hidden", False): continue
        role = "é‡‘é‘«" if msg["role"] == "assistant" else "å®¢æˆ·"
        doc.add_heading(f"{role} - {msg.get('timestamp','')}", level=2)
        if msg.get("code_output"): doc.add_paragraph(f"ã€æ•°æ®ã€‘\n{msg['code_output']}")
        if msg["content"]:
            clean = re.sub(r'```python.*?```', '', msg["content"], flags=re.DOTALL)
            doc.add_paragraph(clean.strip())
        if msg.get("image_path") and os.path.exists(msg["image_path"]):
            try: doc.add_picture(msg["image_path"], width=Inches(5))
            except: pass
    bio = io.BytesIO(); doc.save(bio); bio.seek(0); return bio

# ================= 3. UI å¸ƒå±€ =================

st.markdown("""
<style>
    .stApp { background-color: #0e1117; }
    div[data-testid="stSidebar"] img { border-radius: 50%; border: 3px solid #4CAF50; box-shadow: 0 4px 10px rgba(0,0,0,0.5); }
    .stChatMessage { background-color: rgba(255, 255, 255, 0.05); border-radius: 10px; }
    .code-output { background-color: #e8f5e9; color: #000000 !important; padding: 15px; border-radius: 8px; border-left: 6px solid #2e7d32; font-family: monospace; }
    .monitor-box { border: 2px solid #ff5722; background-color: #fff3e0; padding: 10px; border-radius: 10px; text-align: center; color: #d84315; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# çŠ¶æ€åˆå§‹åŒ–
if "messages" not in st.session_state: st.session_state.messages = load_memory()
if "chat_session" not in st.session_state:
    try:
        model = get_model()
        # è¿‡æ»¤æ‰åæ•°æ®å†ä¼ ç»™æ¨¡å‹
        valid_history = []
        for m in st.session_state.messages:
            if isinstance(m, dict) and not m.get("hidden", False):
                valid_history.append({"role": ("user" if m["role"]=="user" else "model"), "parts": [str(m["content"])]})
        st.session_state.chat_session = model.start_chat(history=valid_history)
    except: pass

if "search_idx" not in st.session_state: st.session_state.search_idx = 0
if "last_search_query" not in st.session_state: st.session_state.last_search_query = ""
if "trigger_scroll" not in st.session_state: st.session_state.trigger_scroll = False
if "monitor_active" not in st.session_state: st.session_state.monitor_active = False

# å¤´åƒåŠ è½½
ai_avatar_path = load_avatar("avatar", "ğŸ‘©â€ğŸ’¼")
user_avatar_path = load_avatar("user", "ğŸ‘¨â€ğŸ’¼")
sidebar_img = ai_avatar_path if ai_avatar_path else "https://api.dicebear.com/9.x/avataaars/svg?seed=Jinxin&clothing=blazerAndShirt"

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.image(sidebar_img, use_container_width=True, caption="ğŸ‘©â€ğŸ’¼ é‡‘é‘« - é«˜çº§åˆä¼™äºº")
    
    # 1. ç›¯ç›˜é›·è¾¾
    with st.expander("ğŸ¯ ä»·æ ¼é›·è¾¾ (ç›¯ç›˜)", expanded=False):
        monitor_ticker = st.text_input("ä»£ç ", value="300750", placeholder="å¦‚ 300750")
        c_m1, c_m2 = st.columns(2)
        monitor_target = c_m1.number_input("ç›®æ ‡", value=200.0, step=1.0)
        monitor_type = c_m2.selectbox("æ¡ä»¶", ["è·Œç ´", "çªç ´"])
        
        if st.button("ğŸ”´ å¯åŠ¨" if not st.session_state.monitor_active else "â¹ï¸ åœæ­¢", type="primary" if not st.session_state.monitor_active else "secondary"):
            st.session_state.monitor_active = not st.session_state.monitor_active
            st.rerun()
            
        if st.session_state.monitor_active:
            st.markdown("<div class='monitor-box'>ğŸ“¡ æ‰«æä¸­...</div>", unsafe_allow_html=True)
            df_m, info_m = get_stock_data_v8(monitor_ticker)
            if df_m is not None:
                # å°è¯•è§£æä»·æ ¼
                try:
                    curr = df_m['Close'].iloc[-1]
                    st.metric("å®æ—¶ä»·", f"{curr:.2f}")
                    triggered = False
                    if monitor_type == "è·Œç ´" and curr < monitor_target: triggered = True
                    if monitor_type == "çªç ´" and curr > monitor_target: triggered = True
                    if triggered:
                        msg = f"æ³¨æ„ï¼{monitor_ticker} ç°ä»· {curr:.2f} è§¦å‘ç›®æ ‡ï¼"
                        st.error(msg)
                        st.session_state.monitor_active = False 
                except: st.warning("æ•°æ®è§£æä¸­...")
            else:
                st.warning("è·å–å¤±è´¥")

    st.divider()
    
    # 2. æœç´¢
    search_query = st.text_input("ğŸ” æœç´¢", placeholder="å…³é”®è¯...", label_visibility="collapsed")
    # æœç´¢å‰å…ˆè¿‡æ»¤éå­—å…¸é¡¹
    match_indices = [i for i, m in enumerate(st.session_state.messages) if isinstance(m, dict) and not m.get("hidden", False) and search_query and search_query in str(m.get("content"))]
    if search_query != st.session_state.last_search_query:
        st.session_state.search_idx = 0; st.session_state.last_search_query = search_query; st.session_state.trigger_scroll = True

    if match_indices:
        c1, c2, c3 = st.columns([1, 2, 1])
        if c1.button("ğŸ”¼"): st.session_state.search_idx = (st.session_state.search_idx - 1) % len(match_indices); st.session_state.trigger_scroll = True; st.rerun()
        if c3.button("ğŸ”½"): st.session_state.search_idx = (st.session_state.search_idx + 1) % len(match_indices); st.session_state.trigger_scroll = True; st.rerun()
        c2.markdown(f"<div style='text-align:center; padding-top:5px;'>{st.session_state.search_idx + 1}/{len(match_indices)}</div>", unsafe_allow_html=True)
        if st.session_state.trigger_scroll:
            try:
                tid = st.session_state.messages[match_indices[st.session_state.search_idx]]["id"]
                import streamlit.components.v1 as components
                components.html(f"<script>setTimeout(function(){{var e=window.parent.document.getElementById('{tid}');if(e)e.scrollIntoView({{behavior:'smooth',block:'center'}});}}, 500);</script>", height=0)
            except: pass
            st.session_state.trigger_scroll = False

    st.divider()
    
    # 3. å¯¼å‡ºä¸æ¸…ç©º
    c_btn1, c_btn2 = st.columns(2)
    if c_btn1.button("ğŸ—‘ï¸ æ¸…ç©º", type="primary", use_container_width=True):
        st.session_state.messages = []; st.session_state.chat_session = None
        if os.path.exists(MEMORY_FILE): os.remove(MEMORY_FILE)
        st.rerun()
    
    doc = create_word_doc(st.session_state.messages)
    c_btn2.download_button("ğŸ“¥ å¯¼å‡º", doc, "æŠ¥å‘Š.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True)
    
    st.divider()
    text_voice = mic_recorder(start_prompt="ğŸ™ï¸ è¯­éŸ³", stop_prompt="â¹ï¸ åœæ­¢", key='rec', format="wav", use_container_width=True)

# --- ä¸»ç•Œé¢ ---
c_h1, c_h2 = st.columns([1, 6])
with c_h1:
    if ai_avatar_path: st.image(ai_avatar_path, width=80)
    else: st.markdown("## ğŸ‘©â€ğŸ’¼")
with c_h2:
    st.title("é‡‘é‘«ï¼šäº‘ç«¯è´¢å¯Œåˆä¼™äºº")

# æ¸²æŸ“æ¶ˆæ¯æµ (å¸¦å®¹é”™)
for i, msg in enumerate(st.session_state.messages):
    # å®¹é”™ï¼šå¦‚æœ msg ä¸æ˜¯å­—å…¸ï¼Œè·³è¿‡
    if not isinstance(msg, dict): continue
    if msg.get("hidden", False): continue
    
    st.markdown(f"<div id='{msg.get('id', '')}'></div>", unsafe_allow_html=True)
    is_curr = search_query and match_indices and i == match_indices[st.session_state.search_idx]

    current_avatar = ai_avatar_path if msg["role"] == "assistant" else user_avatar_path
    if not current_avatar: 
        current_avatar = "ğŸ‘©â€ğŸ’¼" if msg["role"] == "assistant" else "ğŸ‘¨â€ğŸ’¼"

    with st.chat_message(msg["role"], avatar=current_avatar):
        st.caption(f"{msg.get('timestamp','')} {'| ğŸ“' if is_curr else ''}")
        if msg.get("code_output"):
            st.markdown(f"<div class='code-output'>{msg['code_output']}</div>", unsafe_allow_html=True)
        
        content = msg.get("content", "")
        if search_query: content = re.compile(re.escape(search_query), re.IGNORECASE).sub(lambda m: f"<mark>{m.group()}</mark>", content)
        clean = re.sub(r'```python.*?```', '', content, flags=re.DOTALL)
        if is_curr: st.markdown(f"<div class='current-match'>{clean}</div>", unsafe_allow_html=True)
        else: st.markdown(clean, unsafe_allow_html=True)
        
        if msg.get("image_path") and os.path.exists(msg["image_path"]): st.image(msg["image_path"])
        if msg.get("audio_path") and os.path.exists(msg.get("audio_path")): st.audio(msg["audio_path"], format="audio/wav")
        
        with st.expander("ğŸ› ï¸ æ›´å¤šæ“ä½œ", expanded=False):
            c1, c2, c3 = st.columns([1,1,3])
            if c1.button("ğŸš« éšè—", key=f"h_{msg.get('id')}"): toggle_hidden(msg.get("id"))
            if c2.button("ğŸ—‘ï¸ åˆ é™¤", key=f"d_{msg.get('id')}"): delete_message(msg.get("id"))
            st.code(clean, language="text")

u_in_text = st.chat_input("è¯·é—®é‡‘é‘«...")
u_in = None
if text_voice and text_voice['bytes']:
    t = transcribe_audio(text_voice['bytes'])
    if t: u_in = t
elif u_in_text: u_in = u_in_text

if u_in:
    st.session_state.messages.append({"id": str(uuid.uuid4()), "role": "user", "content": u_in, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "hidden": False})
    save_memory(st.session_state.messages)
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    last = st.session_state.messages[-1]
    # å®¹é”™ï¼šç¡®ä¿lastæ˜¯å­—å…¸
    if isinstance(last, dict):
        with st.chat_message("assistant", avatar=ai_avatar_path if ai_avatar_path else "ğŸ‘©â€ğŸ’¼"):
            ph = st.empty(); img = None; out = None; txt = ""
            if st.session_state.chat_session:
                with st.spinner("â˜ï¸ äº‘ç«¯è¿ç®—ä¸­..."):
                    try:
                        resp = st.session_state.chat_session.send_message(last["content"])
                        txt = resp.text
                        codes = re.findall(r'```python(.*?)```', txt, re.DOTALL)
                        if codes: img, out = execute_local_code_and_save(codes[-1])
                        if out: st.markdown(f"<div class='code-output'>{out}</div>", unsafe_allow_html=True)
                        clean = re.sub(r'```python.*?```', '', txt, flags=re.DOTALL)
                        ph.markdown(clean)
                        if img: st.image(img)
                    except Exception as e: st.error(f"Error: {e}")
            af = None
            if "å¼‚å¸¸" not in (out or ""):
                try:
                    spoken = get_spoken_response(txt)
                    ap = os.path.join(AUDIO_DIR, f"v_{int(time.time())}.wav")
                    if save_audio_cloud(spoken, ap): st.audio(ap, format="audio/wav"); af = ap
                except: pass
            st.session_state.messages.append({"id": str(uuid.uuid4()), "role": "assistant", "content": txt, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "hidden": False, "image_path": img, "audio_path": af, "code_output": out})
            save_memory(st.session_state.messages)

if st.session_state.monitor_active:
    time.sleep(5)
    st.rerun()
