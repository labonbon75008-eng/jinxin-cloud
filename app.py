import streamlit as st
import google.generativeai as genai
import os
import time
import json
import uuid
import re
from datetime import datetime
import threading
import requests
import pandas as pd
import warnings
import io
from PIL import Image
import speech_recognition as sr
import edge_tts
import asyncio
import yfinance as yf
from docx import Document
from docx.shared import Inches
from streamlit_mic_recorder import mic_recorder

# ================= 1. åŸºç¡€é…ç½® (æœ€ç®€ç¨³å¥æ¨¡å¼) =================
warnings.filterwarnings("ignore")

# å¿…é¡»æ˜¯ç¬¬ä¸€ä¸ª Streamlit å‘½ä»¤
st.set_page_config(page_title="é‡‘é‘« - æ™ºèƒ½æŠ•èµ„é¡¾é—®", page_icon="ğŸ‘©â€ğŸ’¼", layout="wide")

# è·¯å¾„åˆå§‹åŒ–
MEMORY_FILE = "investment_memory_cloud.json"
CHARTS_DIR = "charts"
AUDIO_DIR = "audio_cache"
for d in [CHARTS_DIR, AUDIO_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# API KEY (å¸¦å®¹é”™æœºåˆ¶ï¼Œé˜²æ­¢é»‘å±)
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    # å¦‚æœæ²¡æœ‰ Secretsï¼Œä½¿ç”¨é»˜è®¤æˆ–è€…ç©ºï¼Œä¿è¯ç•Œé¢èƒ½åŠ è½½å‡ºæ¥
    API_KEY = "AIzaSyAaN5lJUzp7MXQuLyi8NMV5V26aizR8kBU" 

# ================= 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

# --- 1. æé€Ÿæ•°æ®æŠ“å– (æ–°æµªæº) ---
def get_sina_code(symbol):
    s = symbol.strip().upper()
    if s.isdigit():
        if s.startswith('6'): return f"sh{s}"
        if s.startswith('0') or s.startswith('3'): return f"sz{s}"
        if s.startswith('8') or s.startswith('4'): return f"bj{s}"
        if len(s) == 5: return f"hk{s}"
    return s

def get_stock_data_cloud(ticker_symbol):
    """ä¼˜å…ˆä½¿ç”¨æ–°æµªæ¥å£è·å–å®æ—¶æ•°æ®ï¼Œå¤±è´¥åˆ™è¿”å›ç©º"""
    sina_code = get_sina_code(ticker_symbol)
    url = f"http://hq.sinajs.cn/list={sina_code}"
    
    # ç»“æœå®¹å™¨
    price_info = "æš‚æ— æ•°æ®"
    df = None
    
    try:
        # å¼ºåˆ¶ä¸ä½¿ç”¨ä»£ç†ï¼Œç›´è¿æ–°æµª
        r = requests.get(url, timeout=2, proxies={"http": None, "https": None})
        if '=""' not in r.text and len(r.text) > 20:
            parts = r.text.split('"')[1].split(',')
            name = parts[0]
            curr = float(parts[3])
            date = datetime.now().strftime("%H:%M:%S")
            price_info = f"ã€{name}ã€‘ ç°ä»·: {curr:.2f} | æ—¶é—´: {date}"
            
            # é€ ä¸€ä¸ªç®€å•çš„æ•°æ®ç”¨äºç”»å›¾ (å› ä¸ºæ–°æµªä¸ç»™å†å²Kçº¿)
            df = pd.DataFrame({'Close': [curr]}, index=[datetime.now()])
            return df, price_info
    except:
        pass
    
    # å¤‡ç”¨ï¼šYahoo (åªç”¨äºç”»å›¾ï¼Œä¸å¼ºæ±‚)
    try:
        y_sym = ticker_symbol
        if y_sym.isdigit():
            if y_sym.startswith('6'): y_sym += ".SS"
            elif y_sym.startswith('0'): y_sym += ".SZ"
        ticker = yf.Ticker(y_sym)
        hist = ticker.history(period="5d")
        if not hist.empty:
            df = hist[['Close']]
            last = df['Close'].iloc[-1]
            if price_info == "æš‚æ— æ•°æ®":
                price_info = f"ã€Yahooå»¶è¿Ÿæ•°æ®ã€‘æ”¶ç›˜ä»·: {last:.2f}"
            return df, price_info
    except:
        pass

    return None, f"æ— æ³•è·å– {ticker_symbol} æ•°æ®"

# --- 2. è¯­éŸ³ä¸ AI ---
def get_spoken_response(text):
    if not text: return ""
    try:
        model = genai.GenerativeModel("gemini-3-pro-preview")
        response = model.generate_content(f"æˆ‘æ˜¯é‡‘é‘«ï¼Œè¯·å°†æ­¤å†…å®¹è½¬ä¸ºå£è¯­(80å­—å†…)ï¼š\n{text}")
        return response.text
    except: return ""

def save_audio_cloud(text, path):
    try:
        asyncio.run(edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural").save(path))
        return True
    except: return False

def transcribe_audio(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_io = io.BytesIO(audio_bytes)
        with sr.AudioFile(audio_io) as source: audio_data = r.record(source)
        return r.recognize_google(audio_data, language='zh-CN')
    except: return None

# --- 3. æ¨¡å‹é…ç½® ---
SYSTEM_INSTRUCTION = f"""
ä½ å«â€œé‡‘é‘«â€ï¼Œç”¨æˆ·çš„ä¸“å±è´¢å¯Œåˆä¼™äººã€‚å½“å‰æ—¶é—´ï¼š{datetime.now().strftime("%Y-%m-%d")}ã€‚
æŸ¥è¯¢ä»·æ ¼æ—¶ï¼Œè¯·ç¼–å†™ä»£ç è°ƒç”¨ `get_stock_data_cloud(ticker)`ã€‚
ä»£ç æ¨¡æ¿ï¼š
ticker = "600309"
df, info = get_stock_data_cloud(ticker)
if df is not None:
    print(info)
    plt.figure(figsize=(10, 4)) # å°ºå¯¸è°ƒå°ä¸€ç‚¹ï¼Œé˜²æ­¢é»‘å±
    plt.plot(df.index, df['Close'], color='#c2185b')
    plt.title(ticker)
    plt.grid(True, alpha=0.3)
else:
    print(f"æ•°æ®å¤±è´¥: {{info}}")
"""

@st.cache_resource
def get_model():
    genai.configure(api_key=API_KEY)
    return genai.GenerativeModel(model_name="gemini-3-pro-preview", system_instruction=SYSTEM_INSTRUCTION)

def execute_local_code_and_save(code_str):
    image_path = None; text_output = ""; output_capture = io.StringIO()
    try:
        plt.clf(); plt.figure(figsize=(8, 4), dpi=100) 
        local_vars = {'get_stock_data_cloud': get_stock_data_cloud, 'plt': plt, 'pd': pd, 'yf': yf}
        with contextlib.redirect_stdout(output_capture):
            exec(code_str, globals(), local_vars)
        text_output = output_capture.getvalue()
        if plt.get_fignums():
            fig = plt.gcf()
            filename = f"chart_{int(time.time())}.png"
            image_path = os.path.join(CHARTS_DIR, filename)
            fig.savefig(image_path, format="png", bbox_inches='tight'); plt.close(fig)
    except Exception as e: text_output = f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
    return image_path, text_output

# ================= 3. UI å¸ƒå±€ (ç¨³å¥ç‰ˆ) =================

st.markdown("""
<style>
    /* ç®€å•ç²—æš´çš„ CSSï¼Œé˜²æ­¢å†²çª */
    .stApp { background-color: #0e1117; }
    div[data-testid="stSidebar"] img { border-radius: 50%; border: 3px solid #4CAF50; }
    .stChatMessage { background-color: rgba(255, 255, 255, 0.05); }
    .code-output { background-color: #e8f5e9; color: black !important; padding: 10px; border-radius: 5px; }
    .monitor-box { border: 2px solid #ff5722; background-color: #fff3e0; padding: 10px; border-radius: 5px; text-align: center; color: #d84315; }
</style>
""", unsafe_allow_html=True)

# çŠ¶æ€ç®¡ç†
if "messages" not in st.session_state: 
    if os.path.exists(MEMORY_FILE):
        with open(MEMORY_FILE, "r") as f: st.session_state.messages = json.load(f)
    else:
        st.session_state.messages = []

if "chat_session" not in st.session_state:
    try:
        model = get_model()
        history = [{"role": ("user" if m["role"]=="user" else "model"), "parts": [m["content"]]} for m in st.session_state.messages if not m.get("hidden", False)]
        st.session_state.chat_session = model.start_chat(history=history)
    except: pass

if "monitor_active" not in st.session_state: st.session_state.monitor_active = False

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    # ç¨³å¥çš„å›¾ç‰‡åŠ è½½ï¼šç›´æ¥è¯»æ–‡ä»¶ï¼Œä¸æèŠ±å“¨çš„å‡½æ•°
    if os.path.exists("avatar.png"):
        st.image("avatar.png", use_container_width=True, caption="ğŸ‘©â€ğŸ’¼ é‡‘é‘«")
    else:
        st.markdown("# ğŸ‘©â€ğŸ’¼")
        st.caption("é‡‘é‘« (æœªæ‰¾åˆ° avatar.png)")

    st.markdown("### æ§åˆ¶å°")
    
    # ç›¯ç›˜
    with st.expander("ğŸ¯ ç›¯ç›˜é›·è¾¾", expanded=False):
        m_ticker = st.text_input("ä»£ç ", "300750")
        m_target = st.number_input("ç›®æ ‡ä»·", 200.0)
        m_cond = st.selectbox("æ¡ä»¶", ["è·Œç ´", "çªç ´"])
        if st.button("ğŸš€ å¯åŠ¨/åœæ­¢"):
            st.session_state.monitor_active = not st.session_state.monitor_active
            st.rerun()
        
        if st.session_state.monitor_active:
            st.markdown(f"<div class='monitor-box'>ğŸ“¡ ç›‘æ§ä¸­...<br>{m_ticker} @ {m_target}</div>", unsafe_allow_html=True)
            # ç®€å•åˆ·æ–°é€»è¾‘
            df_m, info_m = get_stock_data_cloud(m_ticker)
            if df_m is not None:
                curr = df_m['Close'].iloc[-1]
                st.metric("ç°ä»·", f"{curr:.2f}")
                if (m_cond=="è·Œç ´" and curr<m_target) or (m_cond=="çªç ´" and curr>m_target):
                    st.error(f"è§¦å‘ï¼ç°ä»· {curr}")
                    st.session_state.monitor_active = False

    # åŠŸèƒ½æŒ‰é’®
    c1, c2 = st.columns(2)
    if c1.button("ğŸ—‘ï¸ æ¸…ç©º"):
        st.session_state.messages = []
        st.session_state.chat_session = None
        if os.path.exists(MEMORY_FILE): os.remove(MEMORY_FILE)
        st.rerun()
    
    # å¯¼å‡ºé€»è¾‘
    doc = Document()
    doc.add_heading("ç ”æŠ¥", 0)
    for m in st.session_state.messages:
        if not m.get("hidden"): doc.add_paragraph(f"{m['role']}: {m['content']}")
    bio = io.BytesIO(); doc.save(bio); bio.seek(0)
    c2.download_button("ğŸ“¥ å¯¼å‡º", bio, "report.docx")

    st.divider()
    audio_val = mic_recorder(start_prompt="ğŸ™ï¸ è¯­éŸ³", stop_prompt="â¹ï¸ åœæ­¢", key='mic')

# --- ä¸»ç•Œé¢ ---
# ç®€å•çš„æ ‡é¢˜ï¼Œé¿å…å¸ƒå±€å´©æºƒ
c_t1, c_t2 = st.columns([1, 6])
with c_t1:
    if os.path.exists("avatar.png"): st.image("avatar.png", width=60)
    else: st.write("ğŸ‘©â€ğŸ’¼")
with c_t2: st.title("é‡‘é‘«ï¼šäº‘ç«¯è´¢å¯Œåˆä¼™äºº")

# æ¸²æŸ“æ¶ˆæ¯
for msg in st.session_state.messages:
    if msg.get("hidden"): continue
    
    # ç®€å•çš„å¤´åƒé€»è¾‘
    av = "avatar.png" if msg["role"] == "assistant" and os.path.exists("avatar.png") else None
    if msg["role"] == "user" and os.path.exists("user.png"): av = "user.png"
    
    with st.chat_message(msg["role"], avatar=av):
        if msg.get("code_output"): st.markdown(f"<div class='code-output'>{msg['code_output']}</div>", unsafe_allow_html=True)
        st.markdown(re.sub(r'```python.*?```', '', msg["content"], flags=re.DOTALL))
        if msg.get("image_path") and os.path.exists(msg["image_path"]): st.image(msg["image_path"])
        if msg.get("audio_path") and os.path.exists(msg["audio_path"]): st.audio(msg["audio_path"])

# è¾“å…¥å¤„ç†
prompt = st.chat_input("è¾“å…¥é—®é¢˜...")
user_in = None
if audio_val and audio_val['bytes']: user_in = transcribe_audio(audio_val['bytes'])
elif prompt: user_in = prompt

if user_in:
    st.session_state.messages.append({"role": "user", "content": user_in, "id": str(uuid.uuid4()), "timestamp": str(datetime.now())})
    # ä¿å­˜
    with open(MEMORY_FILE, "w") as f: json.dump(st.session_state.messages, f)
    st.rerun()

# AI å“åº”
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    with st.chat_message("assistant", avatar="avatar.png" if os.path.exists("avatar.png") else None):
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                if not st.session_state.chat_session: 
                    st.session_state.chat_session = get_model().start_chat()
                
                resp = st.session_state.chat_session.send_message(st.session_state.messages[-1]["content"])
                full_text = resp.text
                
                # æ‰§è¡Œä»£ç 
                img_path = None; out_text = None
                codes = re.findall(r'```python(.*?)```', full_text, re.DOTALL)
                if codes: img_path, out_text = execute_local_code_and_save(codes[-1])
                
                # æ˜¾ç¤º
                if out_text: st.markdown(f"<div class='code-output'>{out_text}</div>", unsafe_allow_html=True)
                st.markdown(re.sub(r'```python.*?```', '', full_text, flags=re.DOTALL))
                if img_path: st.image(img_path)
                
                # è¯­éŸ³
                af = None
                spoken = get_spoken_response(full_text)
                if spoken:
                    ap = os.path.join(AUDIO_DIR, f"v_{int(time.time())}.wav")
                    if save_audio_cloud(spoken, ap): 
                        st.audio(ap)
                        af = ap
                
                # ä¿å­˜
                st.session_state.messages.append({
                    "role": "assistant", "content": full_text, "id": str(uuid.uuid4()),
                    "image_path": img_path, "audio_path": af, "code_output": out_text,
                    "timestamp": str(datetime.now())
                })
                with open(MEMORY_FILE, "w") as f: json.dump(st.session_state.messages, f)
                
            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯: {e}")

# ç›¯ç›˜åˆ·æ–°
if st.session_state.monitor_active:
    time.sleep(5)
    st.rerun()
