import streamlit as st
import os
import json
import time
import uuid
import re
import io
import asyncio
import base64
import requests
import pandas as pd
import warnings
import contextlib
import matplotlib
# 1. å¼ºåˆ¶åå°ç»˜å›¾ï¼Œé˜²æ­¢äº‘ç«¯å´©æºƒ
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import yfinance as yf
from docx import Document

# ã€æ ¸å¿ƒä¿®å¤1ã€‘è¯­éŸ³ç»„ä»¶é˜²å´©å¯¼å…¥ï¼šå¦‚æœç¯å¢ƒä¸æ”¯æŒï¼Œç›´æ¥è·³è¿‡ï¼Œç»ä¸æŠ¥é”™å¡æ­»
try:
    from streamlit_mic_recorder import mic_recorder
except ImportError:
    mic_recorder = None

import edge_tts
import speech_recognition as sr
import google.generativeai as genai
from datetime import datetime
from PIL import Image

# ================= 1. ç³»ç»Ÿé…ç½® =================
warnings.filterwarnings("ignore")
st.set_page_config(page_title="é‡‘é‘« - æŠ•èµ„åŠ©ç†", page_icon="ğŸ‘©â€ğŸ’¼", layout="wide")

# CSS å¼ºåˆ¶æ‰‹æœºç«¯ä¼˜åŒ– (é’ˆå¯¹æˆªå›¾é—®é¢˜çš„ä¿®å¤)
st.markdown("""
<style>
    /* å¼ºåˆ¶æ“ä½œåŒºä¸æ¢è¡Œï¼Œå…è®¸æ¨ªå‘æ»‘åŠ¨ */
    div[data-testid="stHorizontalBlock"] { 
        flex-wrap: nowrap !important; 
        overflow-x: auto !important; 
    }
    div[data-testid="stHorizontalBlock"] button { 
        min-width: 60px !important; 
        padding: 0px 5px !important; 
        white-space: nowrap !important;
    }
    .main-title { text-align: center; font-size: 26px; font-weight: bold; color: white; margin-bottom: 10px; }
    .avatar-img { width: 120px; height: 120px; border-radius: 50%; border: 3px solid #4CAF50; margin: 0 auto; display: block; object-fit: cover; }
    /* éšè—ä¸å¿…è¦çš„å…¨å±æŒ‰é’® */
    button[title="View fullscreen"] { display: none; }
</style>
""", unsafe_allow_html=True)

# æ ¸å¿ƒè·¯å¾„
MEMORY_FILE = "investment_memory_v20.json"
CHARTS_DIR = "charts"
AUDIO_DIR = "audio_cache"
FONT_PATH = "SimHei.ttf" 

for d in [CHARTS_DIR, AUDIO_DIR]:
    os.makedirs(d, exist_ok=True)

# API KEY
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    API_KEY = "AIzaSyAaN5lJUzp7MXQuLyi8NMV5V26aizR8kBU"

# ================= 2. é™æ€èµ„æº =================

# ã€æ ¸å¿ƒä¿®å¤2ã€‘å¤´åƒç¡¬ç¼–ç ï¼Œé˜²æ­¢ NameErrorï¼Œé˜²æ­¢ç™½æ¿
DEFAULT_AVATAR = "[https://api.dicebear.com/9.x/avataaars/png?seed=Jinxin&clothing=blazerAndShirt&hairColor=black&skinColor=light&accessories=glasses&top=longHairStraight](https://api.dicebear.com/9.x/avataaars/png?seed=Jinxin&clothing=blazerAndShirt&hairColor=black&skinColor=light&accessories=glasses&top=longHairStraight)"

def get_avatar():
    return DEFAULT_AVATAR

def check_font():
    if not os.path.exists(FONT_PATH):
        try:
            r = requests.get("[https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf](https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf)")
            with open(FONT_PATH, "wb") as f: f.write(r.content)
        except: pass
    if os.path.exists(FONT_PATH):
        fm.fontManager.addfont(FONT_PATH)
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
check_font()

# ================= 3. æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ =================

def clean_text_display(text):
    """ã€æ ¸å¿ƒä¿®å¤3ã€‘å½»åº•åˆ é™¤ä»£ç å—ï¼Œåªç•™æ–‡å­—"""
    # åˆ é™¤ ``` ... ``` ä¹‹é—´çš„æ‰€æœ‰å†…å®¹ (åŒ…æ‹¬æ¢è¡Œ)
    # æ— è®ºæœ‰æ—  python æ ‡ç­¾ï¼Œç»Ÿç»Ÿåˆ æ‰
    text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)
    return text.strip()

# --- A. æ•°æ®å¼•æ“ ---
def get_stock_data(user_input):
    s = str(user_input).strip().upper()
    match = re.search(r"[0-9]{4,6}", s)
    if match: s = match.group()
    else: s = re.sub(r'[^A-Z0-9]', '', s)

    sina_code = s; y_sym = s
    if s.isdigit():
        if len(s)==5: sina_code=f"hk{s}"; y_sym=f"{s}.HK"
        elif len(s)==4: sina_code=f"hk0{s}"; y_sym=f"0{s}.HK"
        elif s.startswith('6'): sina_code=f"sh{s}"; y_sym=f"{s}.SS"
        else: sina_code=f"sz{s}"; y_sym=f"{s}.SZ"
    else: sina_code=f"gb_{s.lower()}"

    info_str = "æš‚æ— æ•°æ®"; curr = 0.0
    
    # Sina
    try:
        url = f"[http://hq.sinajs.cn/list=](http://hq.sinajs.cn/list=){sina_code}"
        r = requests.get(url, headers={'Referer':'[https://finance.sina.com.cn](https://finance.sina.com.cn)'}, timeout=2)
        if len(r.text) > 20:
            parts = r.text.split('"')[1].split(',')
            if len(parts) > 3:
                name = parts[0]
                if "hk" in sina_code: name=parts[1]; curr=float(parts[6]); prev=float(parts[3])
                else: curr=float(parts[3]); prev=float(parts[2])
                pct = ((curr - prev) / prev) * 100 if prev != 0 else 0
                info_str = f"ã€{name}ã€‘ ç°ä»·: {curr:.2f} ({pct:+.2f}%)"
    except: pass

    # Yahoo
    df = None
    try:
        tk = yf.Ticker(y_sym)
        hist = tk.history(period="1mo")
        if not hist.empty: df = hist[['Close']]
    except: pass

    if df is None and curr > 0:
        df = pd.DataFrame({'Close': [curr]*5}, index=pd.date_range(end=datetime.now(), periods=5))
    
    return df, info_str

# --- B. AI å¼•æ“ ---
@st.cache_resource
def get_model():
    genai.configure(api_key=API_KEY)
    prompt = f"""
    ä½ å«â€œé‡‘é‘«â€ï¼Œç”¨æˆ·çš„æŠ•èµ„åŠ©ç†ã€‚å½“å‰æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d')}ã€‚
    ã€é“å¾‹ã€‘
    1. å¿…é¡»è°ƒç”¨ `get_stock_data(code)` è·å–æ•°æ®ã€‚
    2. å¿…é¡»ç”¨ `plt` ç”»å›¾ã€‚
    3. å›ç­”è¦äº²åˆ‡ã€è‡ªç„¶ã€‚
    """
    return genai.GenerativeModel("gemini-3-pro-preview", system_instruction=prompt)

def execute_code(code_str):
    img_path = None; capture = io.StringIO()
    # å¼ºåˆ¶ä¸æ˜¾ç¤ºå›¾è¡¨å¼¹çª—
    safe_code = code_str.replace("plt.show()", "# plt.show()")
    lines = [l for l in safe_code.split('\n') if not l.strip().startswith(('import','from'))]
    safe_code = '\n'.join(lines)

    try:
        plt.close('all'); plt.clf(); plt.figure(figsize=(8, 4))
        with contextlib.redirect_stdout(capture):
            exec(safe_code, globals(), {
                'get_stock_data':get_stock_data, 
                'plt':plt, 'pd':pd, 'yf':yf, 'datetime':datetime,
                'contextlib': contextlib
            })
        if plt.get_fignums():
            fname = f"chart_{int(time.time())}.png"
            img_path = os.path.join(CHARTS_DIR, fname)
            plt.savefig(img_path, bbox_inches='tight', dpi=100); plt.close()
    except Exception as e: pass
    return img_path

# --- C. è¯­éŸ³ ---
async def gen_voice(text, path):
    try: await edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural").save(path); return True
    except: return False

def get_voice_res(text):
    try:
        model = genai.GenerativeModel("gemini-3-pro-preview")
        return model.generate_content(f"è½¬ä¸ºå£è¯­(80å­—å†…)ï¼š\n{text}").text
    except: return ""

def transcribe(audio_bytes):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(io.BytesIO(audio_bytes)) as source:
            return r.recognize_google(r.record(source), language='zh-CN')
    except: return None

# --- D. è®°å¿†ç®¡ç† ---
def load_mem():
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r") as f:
                data = json.load(f)
                return [m for m in data if isinstance(m, dict) and "role" in m]
        except: pass
    return []

def save_mem(msgs):
    try:
        with open(MEMORY_FILE, "w") as f: json.dump(msgs, f, ensure_ascii=False)
    except: pass

def create_doc(msgs, idx=None):
    doc = Document(); doc.add_heading("é‡‘é‘«ç ”æŠ¥", 0)
    targets = [msgs[idx]] if idx is not None else msgs
    for m in targets:
        if not m.get("hidden"):
            doc.add_heading(f"{m['role']}", 2); doc.add_paragraph(clean_text_display(m.get("content","")))
    b = io.BytesIO(); doc.save(b); b.seek(0); return b

# ================= 4. ç•Œé¢å¸ƒå±€ =================

# çŠ¶æ€
if "messages" not in st.session_state: st.session_state.messages = load_mem()
if "monitor" not in st.session_state: st.session_state.monitor = False
if "last_audio" not in st.session_state: st.session_state.last_audio = None

# Session
if "sess" not in st.session_state or st.session_state.sess is None:
    try:
        model = get_model()
        h = [{"role":("user" if m["role"]=="user" else "model"), "parts":[str(m["content"])]} for m in st.session_state.messages if not m.get("hidden")]
        st.session_state.sess = model.start_chat(history=h)
    except: pass

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.image(get_avatar(), width=120)
    st.markdown("<h3 style='text-align:center'>é‡‘é‘«</h3>", unsafe_allow_html=True)
    
    with st.expander("ğŸ¯ ç›¯ç›˜", expanded=True):
        m_code = st.text_input("ä»£ç ", "300750")
        m_tgt = st.number_input("ç›®æ ‡", 0.0)
        if st.button("ğŸ”´ å¯åŠ¨/åœæ­¢"):
            st.session_state.monitor = not st.session_state.monitor
            st.rerun()
        if st.session_state.monitor:
            st.info("ğŸ“¡ ç›‘æ§ä¸­...")
            df, info = get_stock_data(m_code)
            if "ç°ä»·" in str(info):
                try:
                    curr = float(re.search(r"ç°ä»·: (\d+\.\d+)", str(info)).group(1))
                    st.metric("å®æ—¶ä»·", curr)
                    if curr < m_tgt: st.error("è§¦å‘ç›®æ ‡ä»·ï¼"); st.session_state.monitor = False
                except: pass

    st.divider()
    search = st.text_input("ğŸ” æœç´¢")
    
    c1, c2 = st.columns(2)
    if c1.button("ğŸ—‘ï¸ æ¸…ç©º"):
        st.session_state.messages = []; st.session_state.sess = None; save_mem([])
        if os.path.exists(MEMORY_FILE): os.remove(MEMORY_FILE)
        st.rerun()
    c2.download_button("ğŸ“¥ å¯¼å‡º", create_doc(st.session_state.messages), "all.docx")
    
    with st.expander("ğŸ‘ï¸ æ¢å¤"):
        for i, m in enumerate(st.session_state.messages):
            if m.get("hidden"):
                if st.button(f"æ¢å¤: {clean_text_display(m['content'])[:5]}...", key=f"rec_{i}"):
                    st.session_state.messages[i]["hidden"] = False; save_mem(st.session_state.messages); st.rerun()

# --- ä¸»ç•Œé¢ ---
st.markdown("<div class='main-title'>ä½ çš„æŠ•èµ„åŠ©ç†</div>", unsafe_allow_html=True)
st.markdown(f"<div style='display:flex;justify-content:center;margin-bottom:20px;'><img src='{get_avatar()}' class='avatar-img'></div>", unsafe_allow_html=True)

# --- æ¶ˆæ¯æ¸²æŸ“ ---
for i, msg in enumerate(st.session_state.messages):
    if msg.get("hidden"): continue
    if search and search not in str(msg['content']): continue

    av = get_avatar() if msg["role"] == "assistant" else "ğŸ‘¨â€ğŸ’¼"
    
    with st.chat_message(msg["role"], avatar=av):
        # 1. æ–‡æœ¬ (å·²æ¸…æ´—ï¼Œä¸æ˜¾ç¤ºä»£ç )
        st.markdown(clean_text_display(msg["content"]))
        
        # 2. å›¾ç‰‡
        if msg.get("image_path") and os.path.exists(msg.get("image_path")):
            st.image(msg["image_path"])
        
        # 3. è¯­éŸ³
        if msg.get("audio_path") and os.path.exists(msg.get("audio_path")):
            st.audio(msg["audio_path"])
            
        with st.expander("â‹® æ“ä½œ"):
            # å¼ºåˆ¶ç­‰å®½å¸ƒå±€
            c1, c2, c3, c4 = st.columns([1,1,1,1])
            if c1.button("ğŸ“‹", key=f"cp_{i}", help="å¤åˆ¶"): st.code(clean_text_display(msg["content"]))
            if c2.button("ğŸ™ˆ", key=f"hd_{i}", help="éšè—"): 
                st.session_state.messages[i]["hidden"] = True; save_mem(st.session_state.messages); st.rerun()
            if c3.button("ğŸ—‘ï¸", key=f"dl_{i}", help="åˆ é™¤"): 
                del st.session_state.messages[i]; save_mem(st.session_state.messages); st.rerun()
            c4.download_button("ğŸ“¥", create_doc(st.session_state.messages, i), f"msg_{i}.docx", key=f"ex_{i}", help="å¯¼å‡º")

# --- è¾“å…¥å¤„ç† (é˜²å´©æ ¸å¿ƒ) ---
st.markdown("---")
c_voice, c_text = st.columns([1, 5])

# è¯­éŸ³ç»„ä»¶ (åŠ é˜²çˆ†ç›¾ï¼šå¦‚æœ mic_recorder æ²¡åŠ è½½æˆåŠŸï¼Œç›´æ¥è·³è¿‡ï¼Œä¸å´©)
user_input = None
if mic_recorder:
    with c_voice:
        try:
            audio_val = mic_recorder(start_prompt="ğŸ™ï¸", stop_prompt="â¹ï¸", key='mic')
            if audio_val and audio_val['bytes']:
                if audio_val['id'] != st.session_state.last_audio:
                    st.session_state.last_audio = audio_val['id']
                    with st.spinner("è¯†åˆ«ä¸­..."):
                        user_input = transcribe(audio_val['bytes'])
                        if not user_input: st.toast("æœªæ£€æµ‹åˆ°è¯­éŸ³")
        except: 
            st.caption("è¯­éŸ³ä¸å¯ç”¨") # é™çº§å¤„ç†

# æ–‡å­—ç»„ä»¶ (æ”¾åœ¨å¤–å±‚ï¼Œç¡®ä¿æ°¸è¿œæ˜¾ç¤º)
text_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜...")
if text_input: user_input = text_input

if user_input:
    # è®°å½•
    st.session_state.messages.append({"role": "user", "content": user_input, "id": str(uuid.uuid4())})
    save_mem(st.session_state.messages)
    
    # å›ç­”
    with st.chat_message("assistant", avatar=get_avatar()):
        with st.spinner("æ€è€ƒä¸­..."):
            try:
                if not st.session_state.sess: st.rerun()
                
                # æç¤ºè¯æ³¨å…¥
                _, real_info = get_stock_data(user_input[:10])
                sys_prompt = f"""
                å½“å‰æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d')}ã€‚
                ç”¨æˆ·æŸ¥è¯¢ï¼š{user_input}ã€‚
                **çœŸå®æ•°æ®(å¿…é¡»å‚è€ƒ)**ï¼š{real_info}ã€‚
                è¦æ±‚ï¼š
                1. å¿…é¡»åŸºäºä¸Šè¿°çœŸå®æ•°æ®å›ç­”ã€‚
                2. å¿…é¡»ç”Ÿæˆ Python ä»£ç ç”»å›¾ã€‚
                """
                
                resp = st.session_state.sess.send_message(sys_prompt)
                txt = resp.text
                
                # æ‰§è¡Œä»£ç  + æ¸…æ´—
                img_p = None
                codes = re.findall(r'```python(.*?)```', txt, re.DOTALL)
                if codes: img_p = execute_code(codes[-1])
                
                # æ¸…æ´—åçš„æ–‡æœ¬ (ä¸å«ä»£ç )
                clean_txt = clean_text_display(txt)
                
                # è¯­éŸ³ç”Ÿæˆ
                af = None
                spoken = get_voice_res(clean_txt[:500])
                if spoken:
                    af = os.path.join(AUDIO_DIR, f"v_{int(time.time())}.mp3")
                    asyncio.run(gen_voice(spoken, af))
                
                st.session_state.messages.append({
                    "role": "assistant", 
                    "content": clean_txt, # åªå­˜æ¸…æ´—åçš„æ–‡æœ¬
                    "id": str(uuid.uuid4()),
                    "image_path": img_p, 
                    "audio_path": af
                })
                save_mem(st.session_state.messages)
                st.rerun()
            except Exception as e:
                st.error(f"å‡ºé”™: {e}")
                st.session_state.sess = None

if st.session_state.monitor:
    time.sleep(5); st.rerun()
