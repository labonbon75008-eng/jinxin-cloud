import streamlit as st
import google.generativeai as genai
import os
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from docx import Document
from docx.shared import Inches
import re
import json
import time
import io
import uuid
import shutil
from datetime import datetime, timedelta
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
import asyncio
import edge_tts  # ğŸ‘ˆ æ¢å›äº†æœ€å¥½å¬çš„ç½‘ç»œè¯­éŸ³
import requests
import pandas as pd
import warnings
import yfinance as yf
from PIL import Image

# ================= 1. äº‘ç«¯ç¯å¢ƒé…ç½® =================
warnings.filterwarnings("ignore")

# âš ï¸ äº‘ç«¯ä¸éœ€è¦è®¾ç½®ä»£ç†ï¼Œç›´æ¥ç›´è¿ Google å’Œ Yahoo
# PROXY_PORT ... (å·²ç§»é™¤)

# ğŸ”‘ ä» Streamlit Secrets è¯»å– Key (æ›´å®‰å…¨)ï¼Œæˆ–è€…æš‚æ—¶å†™æ­»åœ¨è¿™é‡Œ
# å»ºè®®éƒ¨ç½²æ—¶åœ¨ Streamlit åå°å¡«å…¥ï¼Œè¿™é‡Œä¸ºäº†æ–¹ä¾¿å…ˆå†™æ­»ï¼Œä½†åœ¨å…¬å¼€ä»“åº“è¯·æ³¨æ„å®‰å…¨
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    API_KEY = "AIzaSyAaN5lJUzp7MXQuLyi8NMV5V26aizR8kBU" # å¡«å…¥ä½ çš„ Key

MEMORY_FILE = "investment_memory_cloud.json"
CHARTS_DIR = "charts"
AUDIO_DIR = "audio_cache"

for d in [CHARTS_DIR, AUDIO_DIR]:
    if not os.path.exists(d): os.makedirs(d)

st.set_page_config(page_title="é‡‘é‘« - äº‘ç«¯æ“ç›˜æ‰‹", page_icon="â˜ï¸", layout="wide")

# ================= 2. UI ç¾åŒ– =================
st.markdown("""
<style>
    .stApp { background-color: #0e1117; }
    div[data-testid="stSidebar"] div[data-testid="stImage"] img {
        width: 100%; max-width: 100%; object-fit: cover; border-radius: 12px;
    }
    .stChatMessage { background-color: rgba(255, 255, 255, 0.05); border-radius: 10px; padding: 10px; margin-bottom: 10px; }
    .code-output { background-color: #e8f5e9; color: #000000 !important; padding: 15px; border-radius: 8px; border-left: 6px solid #2e7d32; font-family: 'Consolas', monospace; margin-bottom: 10px; font-size: 0.95em; }
    .monitor-box { border: 2px solid #ff5722; background-color: #fff3e0; padding: 10px; border-radius: 10px; text-align: center; color: #d84315; font-weight: bold; font-size: 0.9em; margin-bottom: 10px; }
</style>
""", unsafe_allow_html=True)

# ================= 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

def load_avatar(filename, default_emoji):
    extensions = ["png", "jpg", "jpeg"]
    base_name = filename.split('.')[0]
    for ext in extensions:
        path = f"{base_name}.{ext}"
        if os.path.exists(path):
            try: Image.open(path); return path
            except: pass
    return default_emoji

# --- äº‘ç«¯æ•°æ®æŠ“å–ç­–ç•¥ ---
# äº‘æœåŠ¡å™¨é€šå¸¸åœ¨æµ·å¤–ï¼Œè®¿é—® Yahoo (yfinance) æå¿«ä¸”ç¨³å®šï¼Œä¸éœ€è¦ä»»ä½• Hack
# è®¿é—®æ–°æµªåè€Œå¯èƒ½è¢«æ‹¦æˆªï¼Œæ‰€ä»¥ç­–ç•¥æ”¹ä¸ºï¼šä¼˜å…ˆ Yahooï¼Œæ–°æµªè¾…åŠ©

def fix_stock_symbol(symbol):
    s = symbol.strip().upper()
    if s.isdigit():
        if s.startswith('6'): return f"{s}.SS"
        if s.startswith('0') or s.startswith('3'): return f"{s}.SZ"
        if len(s) == 5: return f"{s}.HK"
        if len(s) == 4: return f"0{s}.HK"
    return s

def get_stock_data_cloud(ticker_symbol):
    """äº‘ç«¯ä¼˜åŒ–ç‰ˆæ•°æ®æŠ“å–"""
    symbol = fix_stock_symbol(ticker_symbol)
    df = None
    info_str = "æš‚æ— æ•°æ®"
    
    # ä¼˜å…ˆä½¿ç”¨ yfinance (åœ¨æµ·å¤–æœåŠ¡å™¨æå…¶ç¨³å®š)
    try:
        ticker = yf.Ticker(symbol)
        # è·å–æœ€æ–°å³æ—¶æ•°æ®
        hist = ticker.history(period="5d", interval="1d")
        
        if not hist.empty:
            df = hist[['Close']]
            last_price = df['Close'].iloc[-1]
            prev_price = df['Close'].iloc[-2] if len(df) > 1 else last_price
            
            currency = ticker.info.get('currency', '?')
            change_pct = ((last_price - prev_price) / prev_price) * 100
            
            info_str = f"æœ€æ–°ä»·: {last_price:.2f} {currency} ({change_pct:+.2f}%)"
            return df, info_str
    except Exception as e:
        print(f"Yahoo å¤±è´¥: {e}")

    return None, f"æ— æ³•è·å– {symbol} æ•°æ®ï¼Œè¯·æ£€æŸ¥ä»£ç æ˜¯å¦æ­£ç¡®"

# --- è¯­éŸ³åˆæˆ (Edge-TTS) ---
async def generate_audio_edge(text, output_file):
    """ä½¿ç”¨å¾®è½¯è¶…é€¼çœŸè¯­éŸ³ (äº‘ç«¯å¯ç”¨)"""
    try:
        # zh-CN-XiaoxiaoNeural (å¥³å£°ï¼ŒçŸ¥æ€§)
        # zh-CN-YunxiNeural (ç”·å£°ï¼Œç¨³é‡)
        communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
        await communicate.save(output_file)
        return True
    except: return False

def save_audio_cloud(text, output_path):
    """åŒæ­¥åŒ…è£…å¼‚æ­¥å‡½æ•°"""
    try:
        asyncio.run(generate_audio_edge(text, output_path))
        return True
    except: return False

def transcribe_audio(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_io = io.BytesIO(audio_bytes)
        with sr.AudioFile(audio_io) as source: audio_data = r.record(source)
        return r.recognize_google(audio_data, language='zh-CN')
    except: return None

def get_spoken_response(text_analysis):
    if not text_analysis: return ""
    try:
        model = genai.GenerativeModel("gemini-3-pro-preview")
        prompt = f"ä½ æ˜¯é‡‘é‘«ã€‚è¯·å°†æ­¤å†…å®¹è½¬ä¸º80å­—ä»¥å†…çš„å£è¯­ï¼ŒåƒçœŸäººä¸€æ ·äº¤æµï¼š\n{text_analysis}"
        response = model.generate_content(prompt)
        return response.text
    except: return ""

# --- æ¨¡å‹é…ç½® ---
# äº‘ç«¯ä¸éœ€è¦æ‰‹åŠ¨é…ç½®ä¸­æ–‡å­—ä½“ï¼ŒStreamlit Cloud é»˜è®¤æ”¯æŒåŸºæœ¬æ˜¾ç¤º
# å¦‚æœä¹±ç ï¼Œé€šå¸¸éœ€è¦ä¸Šä¼ å­—ä½“æ–‡ä»¶ï¼Œè¿™é‡Œä¸ºäº†ç®€åŒ–å…ˆå¿½ç•¥

current_time_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
SYSTEM_INSTRUCTION = f"""
ä½ å«â€œé‡‘é‘«â€ï¼Œç”¨æˆ·çš„ä¸“å±ç§äººè´¢å¯Œåˆä¼™äººã€‚å½“å‰æ—¥æœŸï¼š{current_time_str}ã€‚

ã€èƒ½åŠ›ã€‘
æŸ¥è¯¢ä»·æ ¼æ—¶ï¼Œè¯·ç¼–å†™ä»£ç è°ƒç”¨ `get_stock_data_cloud(ticker)`ã€‚
Aè‚¡ä»£ç ç›´æ¥å†™æ•°å­— (å¦‚ 600309)ï¼Œç¾è‚¡ç›´æ¥å†™ä»£ç  (å¦‚ AAPL)ã€‚

ã€ä»£ç æ¨¡æ¿ã€‘
ticker = "600309"
df, info = get_stock_data_cloud(ticker)

if df is not None:
    print(f"ã€é‡‘é‘«äº‘ç«¯å®ç›˜ã€‘{{info}}") 
    plt.figure(figsize=(10, 5))
    plt.plot(df.index, df['Close'], label='Close', color='#c2185b') 
    plt.title(f"{{ticker}} Trend")
    plt.grid(True, alpha=0.3)
else:
    print(f"æ•°æ®ä¸å¯ç”¨: {{info}}")
"""

@st.cache_resource
def get_model():
    genai.configure(api_key=API_KEY)
    return genai.GenerativeModel(model_name="gemini-3-pro-preview", system_instruction=SYSTEM_INSTRUCTION)

# --- åŸºç¡€ CRUD ---
def load_memory():
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r", encoding='utf-8') as f: return json.load(f)
        except: pass
    return []

def save_memory(messages):
    try:
        with open(MEMORY_FILE, "w", encoding='utf-8') as f: json.dump(messages, f, ensure_ascii=False, indent=2)
    except: pass

def execute_local_code_and_save(code_str):
    image_path = None; text_output = ""; output_capture = io.StringIO()
    try:
        plt.clf(); plt.figure(figsize=(10, 5), dpi=100) 
        local_vars = {
            'get_stock_data_cloud': get_stock_data_cloud,
            'plt': plt, 'pd': pd, 'yf': yf
        }
        with contextlib.redirect_stdout(output_capture):
            exec(code_str, globals(), local_vars)
        text_output = output_capture.getvalue()
        if plt.get_fignums():
            fig = plt.gcf()
            filename = f"chart_{int(time.time())}.png"
            image_path = os.path.join(CHARTS_DIR, filename)
            fig.savefig(image_path, format="png", bbox_inches='tight'); plt.close(fig)
    except Exception as e: text_output = f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
    return image_path, text_output

# ================= 4. ç•Œé¢ä¸»é€»è¾‘ =================

if "messages" not in st.session_state: st.session_state.messages = load_memory()
if "chat_session" not in st.session_state or st.session_state.chat_session is None:
    try:
        model = get_model()
        history = [{"role": ("user" if m["role"]=="user" else "model"), "parts": [m["content"]]} for m in st.session_state.messages if not m.get("hidden", False)]
        st.session_state.chat_session = model.start_chat(history=history)
    except: pass

with st.sidebar:
    user_avatar = load_avatar("user", "ğŸ‘¨â€ğŸ’¼")
    ai_avatar = load_avatar("avatar", "ğŸ‘©â€ğŸ’¼")
    
    c_av1, c_av2, c_av3 = st.columns([1, 2, 1])
    with c_av2:
        if os.path.exists("avatar.png"): st.image("avatar.png", use_container_width=True)
        else: st.markdown("<div style='text-align: center; font-size: 60px;'>â˜ï¸</div>", unsafe_allow_html=True)
    st.markdown("<h3 style='text-align: center;'>é‡‘é‘« - äº‘ç«¯ç‰ˆ</h3>", unsafe_allow_html=True)

    if st.button("ğŸ—‘ï¸ æ¸…ç©ºè®°å½•", type="primary", use_container_width=True):
        st.session_state.messages = []; st.session_state.chat_session = None
        if os.path.exists(MEMORY_FILE): os.remove(MEMORY_FILE)
        st.rerun()
    
    st.divider()
    text_voice = mic_recorder(start_prompt="ğŸ™ï¸ è¯­éŸ³", stop_prompt="â¹ï¸ åœæ­¢", key='rec', format="wav", use_container_width=True)

# Main
st.markdown("<h2 style='text-align: center;'>ğŸ‘©â€ğŸ’¼ é‡‘é‘«ï¼šæ‚¨çš„äº‘ç«¯è´¢å¯Œåˆä¼™äºº</h2>", unsafe_allow_html=True)

for i, msg in enumerate(st.session_state.messages):
    if msg.get("hidden", False): continue
    
    current_avatar = ai_avatar if msg["role"] == "assistant" else user_avatar
    with st.chat_message(msg["role"], avatar=current_avatar):
        if msg.get("code_output"):
            st.markdown(f"<div class='code-output'>{msg['code_output']}</div>", unsafe_allow_html=True)
        
        content = msg["content"]
        clean = re.sub(r'```python.*?```', '', content, flags=re.DOTALL)
        st.markdown(clean, unsafe_allow_html=True)
        
        if msg.get("image_path") and os.path.exists(msg["image_path"]): st.image(msg["image_path"])
        if msg.get("audio_path") and os.path.exists(msg.get("audio_path")): st.audio(msg["audio_path"], format="audio/wav")

u_in_text = st.chat_input("è¯·é—®é‡‘é‘«...")
u_in = None
if text_voice and text_voice['bytes']:
    t = transcribe_audio(text_voice['bytes'])
    if t: u_in = t
elif u_in_text: u_in = u_in_text

if u_in:
    st.session_state.messages.append({"id": str(uuid.uuid4()), "role": "user", "content": u_in, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "hidden": False})
    save_memory(st.session_state.messages)
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    last = st.session_state.messages[-1]
    with st.chat_message("assistant", avatar=ai_avatar):
        ph = st.empty(); img = None; out = None; txt = ""
        if st.session_state.chat_session:
            with st.spinner("â˜ï¸ äº‘ç«¯å¤§è„‘è¿ç®—ä¸­..."):
                try:
                    resp = st.session_state.chat_session.send_message(last["content"])
                    txt = resp.text
                    codes = re.findall(r'```python(.*?)```', txt, re.DOTALL)
                    if codes: img, out = execute_local_code_and_save(codes[-1])
                    if out: st.markdown(f"<div class='code-output'>{out}</div>", unsafe_allow_html=True)
                    clean = re.sub(r'```python.*?```', '', txt, flags=re.DOTALL)
                    ph.markdown(clean)
                    if img: st.image(img)
                except Exception as e: st.error(f"Error: {e}")
        af = None
        if "å¼‚å¸¸" not in (out or ""):
            try:
                spoken = get_spoken_response(txt)
                ap = os.path.join(AUDIO_DIR, f"v_{int(time.time())}.wav")
                # ä½¿ç”¨ Edge-TTS ç”Ÿæˆ
                if save_audio_cloud(spoken, ap): st.audio(ap, format="audio/wav"); af = ap
            except: pass
        st.session_state.messages.append({"id": str(uuid.uuid4()), "role": "assistant", "content": txt, "hidden": False, "image_path": img, "audio_path": af, "code_output": out})
        save_memory(st.session_state.messages)