import streamlit as st
import os
import json
import time
import uuid
import re
import io
import asyncio
import base64
import requests
import pandas as pd
import warnings
import contextlib # 1. æ ¸å¿ƒä¿®å¤ï¼šç¡®ä¿å¿…é¡»å¯¼å…¥
import sys
import matplotlib
matplotlib.use('Agg') 
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import yfinance as yf
from docx import Document
from streamlit_mic_recorder import mic_recorder
import edge_tts
import speech_recognition as sr
import google.generativeai as genai

# ================= 1. ç³»ç»Ÿé…ç½® =================
warnings.filterwarnings("ignore")
st.set_page_config(page_title="é‡‘é‘« - æŠ•èµ„åŠ©ç†", page_icon="ğŸ‘©â€ğŸ’¼", layout="wide")

# å¼ºåˆ¶æ‰‹æœºç«¯æŒ‰é’®ä¸æ¢è¡Œ (CSS é»‘ç§‘æŠ€)
st.markdown("""
<style>
    /* å¼ºåˆ¶æ“ä½œåŒºçš„åˆ—ä¸æ¢è¡Œ */
    div[data-testid="column"] {
        display: flex;
        flex-direction: column;
    }
    /* é’ˆå¯¹æ‰‹æœºç«¯ä¼˜åŒ–ï¼Œå¼ºåˆ¶æ°´å¹³æ’åˆ— */
    @media (max-width: 640px) {
        div[data-testid="stHorizontalBlock"] {
            flex-wrap: nowrap !important;
            overflow-x: auto;
        }
        div[data-testid="stHorizontalBlock"] button {
            padding: 0px 5px !important;
            font-size: 12px !important;
        }
    }
    .stApp { background-color: #0e1117; }
    .avatar-img { width: 120px; height: 120px; border-radius: 50%; border: 3px solid #4CAF50; margin: 0 auto; display: block; }
    .main-title { text-align: center; font-size: 24px; font-weight: bold; color: white; margin-bottom: 10px; }
    .code-output { background-color: #e8f5e9; color: black !important; padding: 10px; border-radius: 5px; font-family: monospace; }
</style>
""", unsafe_allow_html=True)

# æ ¸å¿ƒè·¯å¾„
MEMORY_FILE = "investment_memory_v14.json"
CHARTS_DIR = "charts"
AUDIO_DIR = "audio_cache"
FONT_PATH = "SimHei.ttf" 

for d in [CHARTS_DIR, AUDIO_DIR]:
    os.makedirs(d, exist_ok=True)

# API KEY
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    API_KEY = "AIzaSyAaN5lJUzp7MXQuLyi8NMV5V26aizR8kBU"

# ================= 2. é™æ€èµ„æºå†…åµŒ =================

# 2. æ ¸å¿ƒä¿®å¤ï¼šå†…åµŒ SVG å¤´åƒ (å½»åº•è§£å†³é»‘å±/ç™½æ¡†)
AVATAR_SVG = """
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100">
<circle cx="50" cy="50" r="48" fill="#e0f2f1" stroke="#4CAF50" stroke-width="3"/>
<path d="M50 25 C35 25 25 35 25 50 C25 65 35 75 50 75 C65 75 75 65 75 50 C75 35 65 25 50 25 Z" fill="#b2dfdb"/>
<path d="M35 50 Q50 65 65 50" stroke="#004d40" stroke-width="3" fill="none"/>
<circle cx="40" cy="40" r="4" fill="#004d40"/>
<circle cx="60" cy="40" r="4" fill="#004d40"/>
<text x="50" y="90" font-size="10" text-anchor="middle" fill="#004d40">JIN XIN</text>
</svg>
"""
# è½¬ä¸º Data URI ä¾› st.markdown ä½¿ç”¨
AVATAR_DATA_URI = f"data:image/svg+xml;base64,{base64.b64encode(AVATAR_SVG.encode()).decode()}"

# ================= 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

# --- A. å­—ä½“ä¸‹è½½ ---
def check_font():
    if not os.path.exists(FONT_PATH):
        try:
            r = requests.get("https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf")
            with open(FONT_PATH, "wb") as f: f.write(r.content)
        except: pass
    if os.path.exists(FONT_PATH):
        fm.fontManager.addfont(FONT_PATH)
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
check_font()

# --- B. æ•°æ®å¼•æ“ (æé€Ÿç‰ˆ) ---
def get_stock_data_v14(ticker):
    """è·å–æ•°æ®"""
    s = ticker.strip().upper().replace(".SS","").replace(".SZ","").replace(".HK","")
    sina_code = s; y_sym = s
    if s.isdigit():
        if len(s)==5: sina_code=f"hk{s}"; y_sym=f"{s}.HK"
        elif len(s)==4: sina_code=f"hk0{s}"; y_sym=f"0{s}.HK"
        elif s.startswith('6'): sina_code=f"sh{s}"; y_sym=f"{s}.SS"
        else: sina_code=f"sz{s}"; y_sym=f"{s}.SZ"
    else: sina_code=f"gb_{s.lower()}"

    info_str = "æš‚æ— æ•°æ®"; curr = 0.0
    
    # Sina
    try:
        url = f"http://hq.sinajs.cn/list={sina_code}"
        r = requests.get(url, headers={'Referer':'https://finance.sina.com.cn'}, timeout=2)
        if len(r.text) > 20:
            parts = r.text.split('"')[1].split(',')
            if len(parts) > 3:
                name = parts[0]
                if "hk" in sina_code: name=parts[1]; curr=float(parts[6]); prev=float(parts[3])
                else: curr=float(parts[3]); prev=float(parts[2])
                pct = ((curr - prev) / prev) * 100 if prev != 0 else 0
                info_str = f"ã€{name}ã€‘ ç°ä»·: {curr:.2f} ({pct:+.2f}%)"
    except: pass

    # Yahoo Chart
    df = None
    try:
        tk = yf.Ticker(y_sym)
        hist = tk.history(period="1mo")
        if not hist.empty: df = hist[['Close']]
    except: pass

    # å…œåº•
    if df is None and curr > 0:
        df = pd.DataFrame({'Close': [curr]*5}, index=pd.date_range(end=datetime.now(), periods=5))
    
    return df, info_str

# --- C. AI å¼•æ“ ---
@st.cache_resource
def get_model():
    genai.configure(api_key=API_KEY)
    prompt = f"""
    ä½ å«â€œé‡‘é‘«â€ï¼Œç”¨æˆ·çš„æŠ•èµ„åŠ©ç†ã€‚å½“å‰æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d')}ã€‚
    è¦æ±‚ï¼š
    1. å¿…é¡»è°ƒç”¨ `get_stock_data_v14(code)`ã€‚
    2. å¿…é¡»ç”»å›¾ã€‚
    3. è¯­æ°”åƒçœŸäººèŠå¤©ï¼Œäº²åˆ‡ã€æœ‰è§‚ç‚¹ã€‚
    ä»£ç æ¨¡æ¿ï¼š
    df, info = get_stock_data_v14("600309")
    if df is not None:
        print(info)
        plt.figure(figsize=(8, 4))
        plt.plot(df.index, df['Close'], color='#c2185b')
        plt.title("Trend")
        plt.grid(True)
    """
    return genai.GenerativeModel("gemini-3-pro-preview", system_instruction=prompt)

def execute_code(code_str):
    """3. æ ¸å¿ƒä¿®å¤ï¼šç¡®ä¿ contextlib å¯ç”¨"""
    img_path = None; output = ""; capture = io.StringIO()
    safe_code = '\n'.join([l for l in code_str.split('\n') if not l.strip().startswith(('import','from'))])
    try:
        plt.close('all'); plt.clf(); plt.figure(figsize=(8, 4))
        # å¼ºåˆ¶ä½¿ç”¨å…¨å±€çš„ contextlib
        with contextlib.redirect_stdout(capture):
            exec(safe_code, globals(), {'get_stock_data_v14':get_stock_data_v14, 'plt':plt, 'pd':pd, 'yf':yf})
        output = capture.getvalue()
        if plt.get_fignums():
            fname = f"chart_{int(time.time())}.png"
            img_path = os.path.join(CHARTS_DIR, fname)
            plt.savefig(img_path, bbox_inches='tight', dpi=100); plt.close()
    except Exception as e: output = f"æ‰§è¡Œé”™è¯¯: {e}"
    return img_path, output

# --- D. è¯­éŸ³ ---
async def gen_voice(text, path):
    try: await edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural").save(path); return True
    except: return False

def get_voice_res(text):
    try:
        model = genai.GenerativeModel("gemini-3-pro-preview")
        return model.generate_content(f"ä½ æ˜¯é‡‘é‘«ï¼Œå°†æ­¤å†…å®¹è½¬ä¸ºèŠå¤©å£è¯­(80å­—å†…)ï¼š\n{text}").text
    except: return ""

def transcribe(audio_bytes):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(io.BytesIO(audio_bytes)) as source:
            return r.recognize_google(r.record(source), language='zh-CN')
    except: return None

# --- E. è®°å¿†ä¸æ–‡ä»¶ ---
def load_mem():
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r") as f:
                data = json.load(f)
                return [m for m in data if isinstance(m, dict) and "role" in m]
        except: pass
    return []

def save_mem(msgs):
    try:
        with open(MEMORY_FILE, "w") as f: json.dump(msgs, f, ensure_ascii=False)
    except: pass

def create_doc(msgs, single_index=None):
    doc = Document(); doc.add_heading("é‡‘é‘«ç ”æŠ¥", 0)
    target_msgs = [msgs[single_index]] if single_index is not None else msgs
    for m in target_msgs:
        if not m.get("hidden"):
            doc.add_heading(f"{m['role']}", 2); doc.add_paragraph(m.get("content",""))
    b = io.BytesIO(); doc.save(b); b.seek(0); return b

# ================= 4. ç•Œé¢å¸ƒå±€ (ä¿®å¤æŒ‰é’®) =================

# çŠ¶æ€
if "messages" not in st.session_state: st.session_state.messages = load_mem()
if "monitor" not in st.session_state: st.session_state.monitor = False

if "sess" not in st.session_state:
    try:
        model = get_model()
        h = [{"role":("user" if m["role"]=="user" else "model"), "parts":[str(m["content"])]} for m in st.session_state.messages if not m.get("hidden")]
        st.session_state.sess = model.start_chat(history=h)
    except: pass

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.markdown(f"<img src='{AVATAR_DATA_URI}' style='width:100px; display:block; margin:0 auto; border-radius:50%;'>", unsafe_allow_html=True)
    st.markdown("<h3 style='text-align:center'>é‡‘é‘«</h3>", unsafe_allow_html=True)
    
    # ç›¯ç›˜
    with st.expander("ğŸ¯ ç›¯ç›˜", expanded=True):
        m_code = st.text_input("ä»£ç ", "300750")
        m_tgt = st.number_input("ç›®æ ‡", 0.0)
        if st.button("ğŸ”´ å¯åŠ¨/åœæ­¢"):
            st.session_state.monitor = not st.session_state.monitor
            st.rerun()
        if st.session_state.monitor:
            st.info("ğŸ“¡ ç›‘æ§è¿è¡Œä¸­...")
            _, info = get_stock_data_v14(m_code)
            if "ç°ä»·" in info:
                try:
                    curr = float(re.search(r"ç°ä»·: (\d+\.\d+)", info).group(1))
                    st.metric("å®æ—¶ä»·", curr)
                    if curr < m_tgt:
                        st.error("è§¦å‘ç›®æ ‡ä»·ï¼"); st.session_state.monitor = False
                except: pass

    st.divider()
    search = st.text_input("ğŸ” æœç´¢")
    
    c1, c2 = st.columns(2)
    if c1.button("ğŸ—‘ï¸ æ¸…ç©º"):
        st.session_state.messages = []; st.session_state.sess = None; save_mem([])
        if os.path.exists(MEMORY_FILE): os.remove(MEMORY_FILE)
        st.rerun()
    c2.download_button("ğŸ“¥ å¯¼å‡º", create_doc(st.session_state.messages), "all.docx")
    
    # æ¢å¤éšè—
    with st.expander("ğŸ‘ï¸ æ¢å¤"):
        for i, m in enumerate(st.session_state.messages):
            if m.get("hidden"):
                if st.button(f"æ¢å¤: {m['content'][:5]}...", key=f"rec_{i}"):
                    st.session_state.messages[i]["hidden"] = False; save_mem(st.session_state.messages); st.rerun()

# --- ä¸»ç•Œé¢ ---
st.markdown("<div class='main-title'>ä½ çš„æŠ•èµ„åŠ©ç†</div>", unsafe_allow_html=True)
# å¼ºåˆ¶ä½¿ç”¨å†…åµŒå¤´åƒï¼Œç»ä¸é»‘å±
st.markdown(f"<img src='{AVATAR_DATA_URI}' class='avatar-img'>", unsafe_allow_html=True)

# --- æ¶ˆæ¯æ¸²æŸ“ ---
for i, msg in enumerate(st.session_state.messages):
    if msg.get("hidden"): continue
    if search and search not in str(msg['content']): continue

    av = AVATAR_DATA_URI if msg["role"] == "assistant" else "ğŸ‘¨â€ğŸ’¼"
    
    with st.chat_message(msg["role"], avatar=av):
        if msg.get("code_output"): 
            st.markdown(f"<div class='code-output'>{msg['code_output']}</div>", unsafe_allow_html=True)
        
        st.markdown(msg["content"])
        
        if msg.get("image_path") and os.path.exists(msg["image_path"]):
            st.image(msg["image_path"])
        if msg.get("audio_path") and os.path.exists(msg["audio_path"]):
            st.audio(msg["audio_path"])
            
        # æ“ä½œåŒºï¼šæŠ˜å èœå• -> å¼ºåˆ¶4åˆ—
        with st.expander("â‹® æ“ä½œ"):
            c_cp, c_hd, c_del, c_ex = st.columns(4)
            if c_cp.button("ğŸ“‹", key=f"cp_{i}"): st.code(msg["content"])
            if c_hd.button("ğŸ™ˆ", key=f"hd_{i}"): 
                st.session_state.messages[i]["hidden"] = True; save_mem(st.session_state.messages); st.rerun()
            if c_del.button("ğŸ—‘ï¸", key=f"dl_{i}"): 
                del st.session_state.messages[i]; save_mem(st.session_state.messages); st.rerun()
            c_ex.download_button("ğŸ“¤", create_doc(st.session_state.messages, i), f"msg_{i}.docx", key=f"ex_{i}")

# --- ç»Ÿä¸€è¾“å…¥å¤„ç† (4. æ ¸å¿ƒä¿®å¤ï¼šç®€åŒ–é€»è¾‘ï¼Œä¿è¯å“åº”) ---
st.markdown("---")
c_voice, c_text = st.columns([1, 5])

# 1. è¯­éŸ³
with c_voice:
    audio_val = mic_recorder(start_prompt="ğŸ™ï¸", stop_prompt="â¹ï¸", key='mic')

# 2. æ–‡å­—
text_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜...")

user_input = None
# ç®€å•çš„äº’æ–¥é€»è¾‘ï¼šæœ‰å­—å…ˆå‘å­—ï¼Œæ²¡å­—çœ‹è¯­éŸ³
if text_input:
    user_input = text_input
elif audio_val and audio_val['bytes']:
    # æ¯æ¬¡å½•éŸ³åªè¦æœ‰æ•°æ®å°±è¯†åˆ«ï¼Œä¸æIDé”äº†ï¼Œé˜²æ­¢é”æ­»
    user_input = transcribe(audio_val['bytes'])

# 3. æ‰§è¡Œ
if user_input:
    # è®°å½•
    st.session_state.messages.append({"role": "user", "content": user_input, "id": str(uuid.uuid4())})
    save_mem(st.session_state.messages)
    
    # å›ç­”
    with st.chat_message("assistant", avatar=AVATAR_DATA_URI):
        with st.spinner("ğŸ‘©â€ğŸ’¼ æ€è€ƒä¸­..."):
            try:
                if not st.session_state.sess: st.rerun()
                resp = st.session_state.sess.send_message(user_input)
                txt = resp.text
                
                # ä»£ç å›¾è¡¨
                img_p = None; out_t = None
                codes = re.findall(r'```python(.*?)```', txt, re.DOTALL)
                if codes: img_p, out_t = execute_code(codes[-1])
                
                # è¯­éŸ³ç”Ÿæˆ
                af = None
                spoken = get_voice_res(txt[:500])
                if spoken:
                    af = os.path.join(AUDIO_DIR, f"v_{int(time.time())}.mp3")
                    asyncio.run(gen_voice(spoken, af))
                
                # ä¿å­˜
                st.session_state.messages.append({
                    "role": "assistant", "content": txt, "id": str(uuid.uuid4()),
                    "image_path": img_p, "audio_path": af, "code_output": out_t
                })
                save_mem(st.session_state.messages)
                st.rerun()
            except Exception as e:
                st.error(f"å‡ºé”™: {e}")

if st.session_state.monitor:
    time.sleep(5); st.rerun()
