import streamlit as st
import os
import time
import json
import uuid
import re
import io
import asyncio
import requests
import pandas as pd
import warnings
import matplotlib
matplotlib.use('Agg') # å¼ºåˆ¶åå°ç»˜å›¾
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import yfinance as yf
from docx import Document
from streamlit_mic_recorder import mic_recorder
import edge_tts
import speech_recognition as sr
import google.generativeai as genai

# ================= 1. åŸºç¡€é…ç½® =================
warnings.filterwarnings("ignore")
st.set_page_config(page_title="é‡‘é‘« - æŠ•èµ„åŠ©ç†", page_icon="ğŸ‘©â€ğŸ’¼", layout="wide")

# è·¯å¾„åˆå§‹åŒ–
MEMORY_FILE = "investment_memory_v15.json"
CHARTS_DIR = "charts"
AUDIO_DIR = "audio_cache"
FONT_PATH = "SimHei.ttf" 

for d in [CHARTS_DIR, AUDIO_DIR]:
    os.makedirs(d, exist_ok=True)

# API KEY è·å–
if "GEMINI_API_KEY" in st.secrets:
    API_KEY = st.secrets["GEMINI_API_KEY"]
else:
    # å¦‚æœæ²¡é…ç½®ï¼Œç»™ä¸€ä¸ªé»˜è®¤å¤‡ç”¨ï¼Œæˆ–è€…æç¤ºç”¨æˆ·
    API_KEY = "AIzaSyAaN5lJUzp7MXQuLyi8NMV5V26aizR8kBU"

# ================= 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

# --- A. å­—ä½“ ---
def check_font():
    if not os.path.exists(FONT_PATH):
        try:
            r = requests.get("https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf")
            with open(FONT_PATH, "wb") as f: f.write(r.content)
        except: pass
    if os.path.exists(FONT_PATH):
        fm.fontManager.addfont(FONT_PATH)
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
check_font()

# --- B. æ•°æ®å¼•æ“ ---
def get_stock_data_v15(ticker):
    s = ticker.strip().upper().replace(".SS","").replace(".SZ","").replace(".HK","")
    sina_code = s; y_sym = s
    if s.isdigit():
        if len(s)==5: sina_code=f"hk{s}"; y_sym=f"{s}.HK"
        elif len(s)==4: sina_code=f"hk0{s}"; y_sym=f"0{s}.HK"
        elif s.startswith('6'): sina_code=f"sh{s}"; y_sym=f"{s}.SS"
        else: sina_code=f"sz{s}"; y_sym=f"{s}.SZ"
    else: sina_code=f"gb_{s.lower()}"

    info_str = "æš‚æ— æ•°æ®"; curr = 0.0
    
    # 1. Sina
    try:
        url = f"http://hq.sinajs.cn/list={sina_code}"
        r = requests.get(url, headers={'Referer':'https://finance.sina.com.cn'}, timeout=2)
        if len(r.text) > 20:
            parts = r.text.split('"')[1].split(',')
            if len(parts) > 3:
                name = parts[0]
                if "hk" in sina_code: name=parts[1]; curr=float(parts[6]); prev=float(parts[3])
                else: curr=float(parts[3]); prev=float(parts[2])
                pct = ((curr - prev) / prev) * 100 if prev != 0 else 0
                info_str = f"ã€{name}ã€‘ ç°ä»·: {curr:.2f} ({pct:+.2f}%)"
    except: pass

    # 2. Yahoo
    df = None
    try:
        tk = yf.Ticker(y_sym)
        hist = tk.history(period="1mo")
        if not hist.empty: df = hist[['Close']]
    except: pass

    # 3. å…œåº•
    if df is None and curr > 0:
        df = pd.DataFrame({'Close': [curr]*5}, index=pd.date_range(end=datetime.now(), periods=5))
    
    return df, info_str

# --- C. AI å¼•æ“ ---
@st.cache_resource
def get_model():
    genai.configure(api_key=API_KEY)
    prompt = f"""
    ä½ å«â€œé‡‘é‘«â€ï¼Œç”¨æˆ·çš„æŠ•èµ„åŠ©ç†ã€‚å½“å‰æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d')}ã€‚
    è¦æ±‚ï¼š
    1. å¿…é¡»è°ƒç”¨ `get_stock_data_v15(code)`ã€‚
    2. å¿…é¡»ç”»å›¾ã€‚
    3. è¯­æ°”åƒçœŸäººèŠå¤©ï¼Œäº²åˆ‡ã€æœ‰è§‚ç‚¹ã€‚
    ä»£ç æ¨¡æ¿ï¼š
    df, info = get_stock_data_v15("600309")
    if df is not None:
        print(info)
        plt.figure(figsize=(8, 4))
        plt.plot(df.index, df['Close'], color='#c2185b')
        plt.title("Trend")
        plt.grid(True)
    """
    return genai.GenerativeModel("gemini-3-pro-preview", system_instruction=prompt)

def execute_code(code_str):
    img_path = None; output = ""; capture = io.StringIO()
    # æ¸…æ´— import
    safe_code = '\n'.join([l for l in code_str.split('\n') if not l.strip().startswith(('import','from'))])
    try:
        plt.close('all'); plt.clf(); plt.figure(figsize=(8, 4))
        with contextlib.redirect_stdout(capture):
            exec(safe_code, globals(), {'get_stock_data_v15':get_stock_data_v15, 'plt':plt, 'pd':pd, 'yf':yf})
        output = capture.getvalue()
        if plt.get_fignums():
            fname = f"chart_{int(time.time())}.png"
            img_path = os.path.join(CHARTS_DIR, fname)
            plt.savefig(img_path, bbox_inches='tight', dpi=100); plt.close()
    except Exception as e: output = f"æ‰§è¡Œé”™è¯¯: {e}"
    return img_path, output

# --- D. è¯­éŸ³ ---
async def gen_voice(text, path):
    try: await edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural").save(path); return True
    except: return False

def get_voice_res(text):
    try:
        model = genai.GenerativeModel("gemini-3-pro-preview")
        return model.generate_content(f"ä½ æ˜¯é‡‘é‘«ï¼Œå°†æ­¤å†…å®¹è½¬ä¸ºèŠå¤©å£è¯­(80å­—å†…)ï¼š\n{text}").text
    except: return ""

def transcribe(audio_bytes):
    r = sr.Recognizer()
    try:
        with sr.AudioFile(io.BytesIO(audio_bytes)) as source:
            return r.recognize_google(r.record(source), language='zh-CN')
    except: return None

# --- E. è®°å¿† ---
def load_mem():
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r") as f:
                data = json.load(f)
                return [m for m in data if isinstance(m, dict) and "role" in m]
        except: pass
    return []

def save_mem(msgs):
    try:
        with open(MEMORY_FILE, "w") as f: json.dump(msgs, f, ensure_ascii=False)
    except: pass

def create_doc(msgs, idx=None):
    doc = Document(); doc.add_heading("é‡‘é‘«ç ”æŠ¥", 0)
    targets = [msgs[idx]] if idx is not None else msgs
    for m in targets:
        if not m.get("hidden"):
            doc.add_heading(f"{m['role']}", 2); doc.add_paragraph(m.get("content",""))
    b = io.BytesIO(); doc.save(b); b.seek(0); return b

# ================= 3. ç•Œé¢å¸ƒå±€ =================

st.markdown("""
<style>
    .stApp { background-color: #0e1117; }
    .main-title { text-align: center; font-size: 28px; font-weight: bold; margin-bottom: 5px; color: white; }
    .avatar-container { display: flex; justify-content: center; margin-bottom: 20px; }
    .avatar-img { width: 120px; height: 120px; border-radius: 50%; border: 3px solid #4CAF50; object-fit: cover; }
    div[data-testid="stSidebar"] button { width: 100%; }
    .code-output { background-color: #e8f5e9; color: #000000 !important; padding: 10px; border-radius: 5px; font-family: monospace; }
</style>
""", unsafe_allow_html=True)

# çŠ¶æ€åˆå§‹åŒ–
if "messages" not in st.session_state: st.session_state.messages = load_mem()
if "monitor" not in st.session_state: st.session_state.monitor = False
# è¯­éŸ³é˜²æŠ–é”
if "last_audio_id" not in st.session_state: st.session_state.last_audio_id = None

# å¤´åƒ (ä¼˜å…ˆæœ¬åœ°ï¼Œå¦åˆ™ç½‘ç»œ)
def get_avatar():
    if os.path.exists("avatar.png"): return "avatar.png"
    return "https://api.dicebear.com/9.x/avataaars/svg?seed=Jinxin&clothing=blazerAndShirt&hairColor=black&skinColor=light"

# --- ä¾§è¾¹æ  ---
with st.sidebar:
    st.image(get_avatar(), use_container_width=True)
    st.markdown("<h3 style='text-align:center'>é‡‘é‘«</h3>", unsafe_allow_html=True)
    
    # ç›¯ç›˜
    with st.expander("ğŸ¯ ç›¯ç›˜", expanded=True):
        m_code = st.text_input("ä»£ç ", "300750")
        m_tgt = st.number_input("ç›®æ ‡", 0.0)
        if st.button("ğŸ”´ å¯åŠ¨/åœæ­¢"):
            st.session_state.monitor = not st.session_state.monitor
            st.rerun()
        if st.session_state.monitor:
            st.info("ğŸ“¡ ç›‘æ§ä¸­...")
            _, info = get_stock_data_v15(m_code)
            if "ç°ä»·" in info:
                try:
                    curr = float(re.search(r"ç°ä»·: (\d+\.\d+)", info).group(1))
                    st.metric("å®æ—¶ä»·", curr)
                    if curr < m_tgt: st.error("è§¦å‘ç›®æ ‡ï¼"); st.session_state.monitor = False
                except: pass

    st.divider()
    search = st.text_input("ğŸ” æœç´¢")
    
    c1, c2 = st.columns(2)
    if c1.button("ğŸ—‘ï¸ æ¸…ç©º"):
        st.session_state.messages = []; save_mem([])
        if os.path.exists(MEMORY_FILE): os.remove(MEMORY_FILE)
        st.rerun()
    c2.download_button("ğŸ“¥ å¯¼å‡º", create_doc(st.session_state.messages), "all.docx")
    
    with st.expander("ğŸ‘ï¸ æ¢å¤"):
        for i, m in enumerate(st.session_state.messages):
            if m.get("hidden"):
                if st.button(f"æ¢å¤: {m['content'][:5]}...", key=f"rec_{i}"):
                    st.session_state.messages[i]["hidden"] = False; save_mem(st.session_state.messages); st.rerun()

# --- ä¸»ç•Œé¢ ---
st.markdown("<div class='main-title'>ä½ çš„æŠ•èµ„åŠ©ç†</div>", unsafe_allow_html=True)
# ä½¿ç”¨ HTML æ¸²æŸ“å¤´åƒï¼Œç¡®ä¿å±…ä¸­ä¸”ä¸è£‚å›¾
st.markdown(f"""
<div class='avatar-container'>
    <img src='{get_avatar()}' class='avatar-img'>
</div>
""", unsafe_allow_html=True)

# --- æ¶ˆæ¯æ¸²æŸ“ ---
for i, msg in enumerate(st.session_state.messages):
    if msg.get("hidden"): continue
    if search and search not in str(msg['content']): continue

    av = get_avatar() if msg["role"] == "assistant" else "ğŸ‘¨â€ğŸ’¼"
    
    with st.chat_message(msg["role"], avatar=av):
        if msg.get("code_output"): 
            st.markdown(f"<div class='code-output'>{msg['code_output']}</div>", unsafe_allow_html=True)
        
        st.markdown(msg["content"])
        
        if msg.get("image_path") and os.path.exists(msg["image_path"]):
            st.image(msg["image_path"])
        if msg.get("audio_path") and os.path.exists(msg["audio_path"]):
            st.audio(msg["audio_path"])
            
        # æ“ä½œåŒº (æ‰‹æœºç«¯å‹å¥½)
        # ä½¿ç”¨ st.columns å¸ƒå±€ï¼Œä½†æ³¨æ„æ‰‹æœºç«¯å¯èƒ½éœ€è¦ popover æ›´ä½³
        # è¿™é‡Œä½¿ç”¨ columns å¹¶é…åˆ emoji ä¿æŒç´§å‡‘
        col_list = st.columns([1,1,1,1])
        if col_list[0].button("ğŸ“‹", key=f"cp_{i}", help="å¤åˆ¶"): st.code(msg["content"])
        if col_list[1].button("ğŸ™ˆ", key=f"hd_{i}", help="éšè—"): 
            st.session_state.messages[i]["hidden"] = True; save_mem(st.session_state.messages); st.rerun()
        if col_list[2].button("ğŸ—‘ï¸", key=f"dl_{i}", help="åˆ é™¤"): 
            del st.session_state.messages[i]; save_mem(st.session_state.messages); st.rerun()
        col_list[3].download_button("ğŸ“¥", create_doc(st.session_state.messages, i), f"msg_{i}.docx", key=f"ex_{i}", help="å¯¼å‡ºæ­¤æ¡")

# --- ç»Ÿä¸€è¾“å…¥å¤„ç† (å…³é”®ä¿®å¤ï¼šçŠ¶æ€æœºæ¨¡å¼) ---
st.markdown("---")
c_voice, c_text = st.columns([1, 5])

# 1. é‡‡é›†è¾“å…¥
voice_input = None
text_input = st.chat_input("è¯·è¾“å…¥é—®é¢˜...")

with c_voice:
    audio_val = mic_recorder(start_prompt="ğŸ™ï¸", stop_prompt="â¹ï¸", key='mic')

# 2. åˆ¤æ–­è¾“å…¥æº
final_input = None

if text_input:
    final_input = text_input
elif audio_val and audio_val['bytes']:
    # åªæœ‰ ID å˜äº†æ‰ç®—æ–°è¾“å…¥
    if audio_val['id'] != st.session_state.last_audio_id:
        st.session_state.last_audio_id = audio_val['id']
        with st.spinner("ğŸ‘‚ è¯†åˆ«ä¸­..."):
            final_input = transcribe(audio_val['bytes'])

# 3. å¤„ç†è¾“å…¥ (å¦‚æœå­˜åœ¨)
if final_input:
    # å­˜å…¥ç”¨æˆ·æ¶ˆæ¯
    st.session_state.messages.append({"role": "user", "content": final_input, "id": str(uuid.uuid4())})
    save_mem(st.session_state.messages)
    st.rerun() # ç«‹å³åˆ·æ–°ï¼Œæ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ï¼Œè¿›å…¥ä¸‹ä¸€æ­¥

# 4. è§¦å‘ AI å›ç­” (å¦‚æœæœ€åä¸€æ¡æ˜¯ç”¨æˆ·å‘çš„)
if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    last_msg = st.session_state.messages[-1]
    
    with st.chat_message("assistant", avatar=get_avatar()):
        with st.spinner("ğŸ‘©â€ğŸ’¼ æ€è€ƒä¸­..."):
            try:
                # åˆå§‹åŒ– Session (æ¯æ¬¡éƒ½æ–°å»ºï¼Œé˜²æ­¢æ–­è¿)
                model = get_model()
                # ç®€å•çš„å†å²æ„å»º
                h_list = [{"role":("user" if m["role"]=="user" else "model"), "parts":[str(m["content"])]} 
                          for m in st.session_state.messages[:-1] if not m.get("hidden")]
                chat = model.start_chat(history=h_list)
                
                # å‘é€
                resp = chat.send_message(last_msg["content"])
                txt = resp.text
                
                # ä»£ç æ‰§è¡Œ
                img_p = None; out_t = None
                codes = re.findall(r'```python(.*?)```', txt, re.DOTALL)
                if codes: img_p, out_t = execute_code(codes[-1])
                
                # è¯­éŸ³ç”Ÿæˆ
                af = None
                spoken = get_voice_res(txt[:500])
                if spoken:
                    af = os.path.join(AUDIO_DIR, f"v_{int(time.time())}.mp3")
                    asyncio.run(gen_voice(spoken, af))
                
                # å­˜å…¥ AI æ¶ˆæ¯
                st.session_state.messages.append({
                    "role": "assistant", "content": txt, "id": str(uuid.uuid4()),
                    "image_path": img_p, "audio_path": af, "code_output": out_t
                })
                save_mem(st.session_state.messages)
                st.rerun() # å†æ¬¡åˆ·æ–°ï¼Œæ˜¾ç¤ºç»“æœ
                
            except Exception as e:
                st.error(f"å‡ºé”™: {e}")

# ç›¯ç›˜å¾ªç¯
if st.session_state.monitor:
    time.sleep(5); st.rerun()
