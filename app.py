import streamlit as st
import google.generativeai as genai
import os
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from docx import Document
from docx.shared import Inches
import re
import json
import time
import io
import uuid
import shutil
from datetime import datetime, timedelta
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
import asyncio
import edge_tts  # äº‘ç«¯è¯­éŸ³åº“
import requests
import pandas as pd
import warnings
import contextlib # ã€å·²ä¿®å¤ã€‘è¡¥å›æ¼æ‰çš„åº“
import sys
import yfinance as yf
from PIL import Image

# ================= 1. äº‘ç«¯ç¯å¢ƒé…ç½® =================
warnings.filterwarnings("ignore")

# âš ï¸ äº‘ç«¯é€šå¸¸ä¸éœ€è¦ä»£ç†ï¼Œå·²ç§»é™¤ PROXY è®¾ç½®
# å¦‚æœä½ åœ¨æœ¬åœ°è¿è¡Œæ­¤ç‰ˆæœ¬ä¸”éœ€è¦ç¿»å¢™ï¼Œè¯·è‡ªè¡Œæ¢å¤ os.environ è®¾ç½®

# API KEY (å»ºè®®åœ¨ Streamlit Secrets ä¸­é…ç½®ï¼Œè¿™é‡Œåšå…¼å®¹)
try:
    API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    API_KEY = "AIzaSyAaN5lJUzp7MXQuLyi8NMV5V26aizR8kBU" 

MEMORY_FILE = "investment_memory_cloud.json"
CHARTS_DIR = "charts"
AUDIO_DIR = "audio_cache"

for d in [CHARTS_DIR, AUDIO_DIR]:
    if not os.path.exists(d): os.makedirs(d)

# ã€UIä¿®å¤ã€‘é¡µé¢å›¾æ ‡å°è¯•ä½¿ç”¨æœ¬åœ°å›¾ç‰‡ï¼ˆå¦‚æœä¸æ”¯æŒåˆ™ç”¨ Emojiï¼‰
st.set_page_config(page_title="é‡‘é‘« - äº‘ç«¯ç§äººé¡¾é—®", page_icon="ğŸ‘©â€ğŸ’¼", layout="wide")

# ================= 2. UI ç¾åŒ– =================
st.markdown("""
<style>
    .stApp { background-color: #0e1117; }
    div[data-testid="stSidebar"] div[data-testid="stImage"] img {
        width: 100%; max-width: 100%; object-fit: cover; border-radius: 12px;
    }
    .stChatMessage { background-color: rgba(255, 255, 255, 0.05); border-radius: 10px; padding: 10px; margin-bottom: 10px; }
    mark { background-color: #ffeb3b; color: #000000 !important; border-radius: 4px; padding: 0.2em; font-weight: bold; }
    .current-match { border: 2px solid #ff4b4b; padding: 10px; border-radius: 10px; background-color: rgba(255, 75, 75, 0.05); display: block; }
    .code-output { background-color: #e8f5e9; color: #000000 !important; padding: 15px; border-radius: 8px; border-left: 6px solid #2e7d32; font-family: 'Consolas', monospace; margin-bottom: 10px; font-size: 0.95em; }
    .monitor-box { border: 2px solid #ff5722; background-color: #fff3e0; padding: 10px; border-radius: 10px; text-align: center; color: #d84315; font-weight: bold; font-size: 0.9em; margin-bottom: 10px; }
</style>
""", unsafe_allow_html=True)

# ================= 3. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° =================

def load_avatar(filename, default_emoji):
    """åŠ è½½æœ¬åœ°å¤´åƒ"""
    extensions = ["png", "jpg", "jpeg"]
    base_name = filename.split('.')[0]
    for ext in extensions:
        path = f"{base_name}.{ext}"
        if os.path.exists(path):
            return path # è¿”å›è·¯å¾„
    return default_emoji # æ‰¾ä¸åˆ°æ–‡ä»¶åˆ™è¿”å› Emoji

# --- æ•°æ®æŠ“å– (äº‘ç«¯ç­–ç•¥ï¼šä¼˜å…ˆ Yahoo) ---
def fix_stock_symbol(symbol):
    s = symbol.strip().upper()
    if s.isdigit():
        if s.startswith('6'): return f"{s}.SS"
        if s.startswith('0') or s.startswith('3'): return f"{s}.SZ"
        if len(s) == 5: return f"{s}.HK"
        if len(s) == 4: return f"0{s}.HK"
    return s

def get_stock_data_cloud(ticker_symbol):
    """äº‘ç«¯æ•°æ®æŠ“å–ï¼šä¸»è¦ä¾èµ– yfinance"""
    symbol = fix_stock_symbol(ticker_symbol)
    df = None
    info_str = "æš‚æ— æ•°æ®"
    
    try:
        ticker = yf.Ticker(symbol)
        # è·å–æœ€è¿‘5å¤©æ•°æ®
        hist = ticker.history(period="5d", interval="1d")
        
        if not hist.empty:
            df = hist[['Close']]
            last_price = df['Close'].iloc[-1]
            last_date = df.index[-1].strftime("%Y-%m-%d")
            currency = ticker.info.get('currency', '?')
            
            # å°è¯•è®¡ç®—æ¶¨è·Œ
            change_str = ""
            if len(df) >= 2:
                prev = df['Close'].iloc[-2]
                change = last_price - prev
                pct = (change / prev) * 100
                change_str = f" ({'+' if change>0 else ''}{change:.2f} / {pct:.2f}%)"
            
            info_str = f"æ—¥æœŸ: {last_date} | æœ€æ–°ä»·: {last_price:.2f} {currency}{change_str}"
            return df, info_str
    except Exception as e:
        print(f"Yahoo Error: {e}")

    return None, f"æ•°æ®è·å–å¤±è´¥ ({symbol})ï¼Œè¯·æ£€æŸ¥ä»£ç æˆ–ç½‘ç»œ"

# --- è¯­éŸ³åˆæˆ (Edge-TTS) ---
async def generate_audio_edge(text, output_file):
    """å¾®è½¯ Edge è¯­éŸ³ (äº‘ç«¯æ ¸å¿ƒ)"""
    try:
        # ä½¿ç”¨æ™“æ™“ (Xiaoxiao) - çŸ¥æ€§å¥³å£°
        communicate = edge_tts.Communicate(text, "zh-CN-XiaoxiaoNeural")
        await communicate.save(output_file)
        return True
    except: return False

def save_audio_cloud(text, output_path):
    """åŒæ­¥åŒ…è£…å™¨"""
    try:
        asyncio.run(generate_audio_edge(text, output_path))
        return True
    except: return False

def transcribe_audio(audio_bytes):
    r = sr.Recognizer()
    try:
        audio_io = io.BytesIO(audio_bytes)
        with sr.AudioFile(audio_io) as source: audio_data = r.record(source)
        return r.recognize_google(audio_data, language='zh-CN')
    except: return None

def get_spoken_response(text_analysis):
    if not text_analysis: return ""
    try:
        model = genai.GenerativeModel("gemini-3-pro-preview")
        prompt = f"ä½ æ˜¯é‡‘é‘«ã€‚è¯·å°†æ­¤å†…å®¹è½¬ä¸º80å­—ä»¥å†…çš„å£è¯­ï¼ŒåƒçœŸäººä¸€æ ·äº¤æµï¼š\n{text_analysis}"
        response = model.generate_content(prompt)
        return response.text
    except: return ""

# --- ç³»ç»Ÿé…ç½® ---
current_time_str = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
SYSTEM_INSTRUCTION = f"""
ä½ å«â€œé‡‘é‘«â€ï¼Œç”¨æˆ·çš„ä¸“å±ç§äººè´¢å¯Œåˆä¼™äººã€‚å½“å‰æ—¥æœŸï¼š{current_time_str}ã€‚

ã€èƒ½åŠ›ã€‘
æŸ¥è¯¢ä»·æ ¼æ—¶ï¼Œè¯·ç¼–å†™ä»£ç è°ƒç”¨ `get_stock_data_cloud(ticker)`ã€‚
Aè‚¡ä»£ç ç›´æ¥å†™æ•°å­— (å¦‚ 600309)ï¼Œç¾è‚¡ç›´æ¥å†™ä»£ç  (å¦‚ AAPL)ã€‚

ã€ä»£ç æ¨¡æ¿ã€‘
ticker = "300750" # å®å¾·æ—¶ä»£
df, info = get_stock_data_cloud(ticker)

if df is not None:
    print(f"ã€é‡‘é‘«äº‘ç«¯å®ç›˜ã€‘{{info}}") 
    plt.figure(figsize=(10, 5))
    plt.plot(df.index, df['Close'], label='Close', color='#c2185b') 
    plt.title(f"{{ticker}} Trend")
    plt.grid(True, alpha=0.3)
else:
    print(f"æ•°æ®ä¸å¯ç”¨: {{info}}")
"""

@st.cache_resource
def get_model():
    genai.configure(api_key=API_KEY)
    return genai.GenerativeModel(model_name="gemini-3-pro-preview", system_instruction=SYSTEM_INSTRUCTION)

# --- åŸºç¡€ CRUD ---
def load_memory():
    if os.path.exists(MEMORY_FILE):
        try:
            with open(MEMORY_FILE, "r", encoding='utf-8') as f: return json.load(f)
        except: pass
    return []

def save_memory(messages):
    try:
        with open(MEMORY_FILE, "w", encoding='utf-8') as f: json.dump(messages, f, ensure_ascii=False, indent=2)
    except: pass

def delete_message(msg_id):
    for i, msg in enumerate(st.session_state.messages):
        if msg["id"] == msg_id:
            del st.session_state.messages[i]; save_memory(st.session_state.messages); st.rerun(); break

def toggle_hidden(msg_id):
    for msg in st.session_state.messages:
        if msg["id"] == msg_id:
            msg["hidden"] = not msg.get("hidden", False); save_memory(st.session_state.messages); st.rerun(); break

def execute_local_code_and_save(code_str):
    image_path = None; text_output = ""; output_capture = io.StringIO()
    try:
        plt.clf(); plt.figure(figsize=(10, 5), dpi=100) 
        local_vars = {
            'get_stock_data_cloud': get_stock_data_cloud,
            'plt': plt, 'pd': pd, 'yf': yf
        }
        with contextlib.redirect_stdout(output_capture):
            exec(code_str, globals(), local_vars)
        text_output = output_capture.getvalue()
        if plt.get_fignums():
            fig = plt.gcf()
            filename = f"chart_{int(time.time())}.png"
            image_path = os.path.join(CHARTS_DIR, filename)
            fig.savefig(image_path, format="png", bbox_inches='tight'); plt.close(fig)
    except Exception as e: text_output = f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"
    return image_path, text_output

def create_word_doc(messages):
    doc = Document(); doc.add_heading("é‡‘é‘«è´¢å¯ŒæŠ¥å‘Š", 0)
    for msg in messages:
        if msg.get("hidden", False): continue
        role = "é‡‘é‘«" if msg["role"] == "assistant" else "å®¢æˆ·"
        doc.add_heading(f"{role} - {msg.get('timestamp','')}", level=2)
        if msg.get("code_output"): doc.add_paragraph(f"ã€æ•°æ®ã€‘\n{msg['code_output']}")
        if msg["content"]:
            clean = re.sub(r'```python.*?```', '', msg["content"], flags=re.DOTALL)
            doc.add_paragraph(clean.strip())
        if msg.get("image_path") and os.path.exists(msg["image_path"]):
            try: doc.add_picture(msg["image_path"], width=Inches(5))
            except: pass
    bio = io.BytesIO(); doc.save(bio); bio.seek(0); return bio

# ================= 4. ç•Œé¢ä¸»é€»è¾‘ =================

if "messages" not in st.session_state: st.session_state.messages = load_memory()
if "chat_session" not in st.session_state or st.session_state.chat_session is None:
    try:
        model = get_model()
        history = [{"role": ("user" if m["role"]=="user" else "model"), "parts": [m["content"]]} for m in st.session_state.messages if not m.get("hidden", False)]
        st.session_state.chat_session = model.start_chat(history=history)
    except: pass

# çŠ¶æ€åˆå§‹åŒ–
if "search_idx" not in st.session_state: st.session_state.search_idx = 0
if "last_search_query" not in st.session_state: st.session_state.last_search_query = ""
if "trigger_scroll" not in st.session_state: st.session_state.trigger_scroll = False
if "monitor_active" not in st.session_state: st.session_state.monitor_active = False

# --- ä¾§è¾¹æ  (åŠŸèƒ½å…¨å›å½’) ---
with st.sidebar:
    # 1. å¤´åƒé€»è¾‘
    user_avatar = load_avatar("user", "ğŸ‘¨â€ğŸ’¼")
    ai_avatar = load_avatar("avatar", "ğŸ‘©â€ğŸ’¼")
    
    # é‡‘é‘«å¤´åƒå±•ç¤º
    c_av1, c_av2, c_av3 = st.columns([1, 2, 1])
    with c_av2:
        if os.path.exists(ai_avatar) and ai_avatar != "ğŸ‘©â€ğŸ’¼": 
            st.image(ai_avatar, use_container_width=True)
        else: 
            st.markdown("<div style='text-align: center; font-size: 60px;'>ğŸ‘©â€ğŸ’¼</div>", unsafe_allow_html=True)
    st.markdown("<h3 style='text-align: center;'>é‡‘é‘« - äº‘ç«¯åˆä¼™äºº</h3>", unsafe_allow_html=True)

    # 2. ç›¯ç›˜é›·è¾¾ (å›å½’!)
    with st.expander("ğŸ¯ ä»·æ ¼é›·è¾¾ (ç›¯ç›˜)", expanded=False):
        monitor_ticker = st.text_input("ä»£ç ", value="300750", placeholder="å¦‚ 300750")
        c_m1, c_m2 = st.columns(2)
        monitor_target = c_m1.number_input("ç›®æ ‡", value=200.0, step=1.0)
        monitor_type = c_m2.selectbox("æ¡ä»¶", ["è·Œç ´", "çªç ´"])
        
        if st.button("ğŸ”´ å¯åŠ¨" if not st.session_state.monitor_active else "â¹ï¸ åœæ­¢", type="primary" if not st.session_state.monitor_active else "secondary"):
            st.session_state.monitor_active = not st.session_state.monitor_active
            st.rerun()
            
        if st.session_state.monitor_active:
            st.markdown("<div class='monitor-box'>ğŸ“¡ æ‰«æä¸­...</div>", unsafe_allow_html=True)
            # äº‘ç«¯ç›¯ç›˜é€»è¾‘
            df_m, info_m = get_stock_data_cloud(monitor_ticker)
            if df_m is not None:
                curr = df_m['Close'].iloc[-1]
                st.metric("å®æ—¶ä»·", f"{curr:.2f}")
                
                triggered = False
                if monitor_type == "è·Œç ´" and curr < monitor_target: triggered = True
                if monitor_type == "çªç ´" and curr > monitor_target: triggered = True
                
                if triggered:
                    msg = f"æ³¨æ„ï¼{monitor_ticker} ç°ä»· {curr:.2f} è§¦å‘ç›®æ ‡ï¼"
                    st.error(msg)
                    st.session_state.monitor_active = False # è§¦å‘å³åœ
            else:
                st.warning("è·å–å¤±è´¥")

    st.divider()
    
    # 3. æœç´¢ (å›å½’!)
    search_query = st.text_input("ğŸ” æœç´¢", placeholder="å…³é”®è¯...", label_visibility="collapsed")
    match_indices = [i for i, m in enumerate(st.session_state.messages) if not m.get("hidden", False) and search_query and search_query in m["content"]]
    if search_query != st.session_state.last_search_query:
        st.session_state.search_idx = 0; st.session_state.last_search_query = search_query; st.session_state.trigger_scroll = True

    if match_indices:
        c1, c2, c3 = st.columns([1, 2, 1])
        if c1.button("ğŸ”¼"): st.session_state.search_idx = (st.session_state.search_idx - 1) % len(match_indices); st.session_state.trigger_scroll = True; st.rerun()
        if c3.button("ğŸ”½"): st.session_state.search_idx = (st.session_state.search_idx + 1) % len(match_indices); st.session_state.trigger_scroll = True; st.rerun()
        c2.markdown(f"<div style='text-align:center; padding-top:5px;'>{st.session_state.search_idx + 1}/{len(match_indices)}</div>", unsafe_allow_html=True)
        if st.session_state.trigger_scroll:
            tid = st.session_state.messages[match_indices[st.session_state.search_idx]]["id"]
            import streamlit.components.v1 as components
            components.html(f"<script>setTimeout(function(){{var e=window.parent.document.getElementById('{tid}');if(e)e.scrollIntoView({{behavior:'smooth',block:'center'}});}}, 500);</script>", height=0)
            st.session_state.trigger_scroll = False

    st.divider()
    
    # 4. å¯¼å‡ºä¸æ¸…ç©º (å›å½’!)
    c_btn1, c_btn2 = st.columns(2)
    if c_btn1.button("ğŸ—‘ï¸ æ¸…ç©º", type="primary", use_container_width=True):
        st.session_state.messages = []; st.session_state.chat_session = None
        if os.path.exists(MEMORY_FILE): os.remove(MEMORY_FILE)
        st.rerun()
    
    doc = create_word_doc(st.session_state.messages)
    c_btn2.download_button("ğŸ“¥ å¯¼å‡º", doc, "æŠ¥å‘Š.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document", use_container_width=True)
    
    st.divider()
    text_voice = mic_recorder(start_prompt="ğŸ™ï¸ è¯­éŸ³", stop_prompt="â¹ï¸ åœæ­¢", key='rec', format="wav", use_container_width=True)

# Main
st.markdown("<h2 style='text-align: center;'>ğŸ‘©â€ğŸ’¼ é‡‘é‘«ï¼šäº‘ç«¯è´¢å¯Œåˆä¼™äºº</h2>", unsafe_allow_html=True)

for i, msg in enumerate(st.session_state.messages):
    if msg.get("hidden", False): continue
    st.markdown(f"<div id='{msg['id']}'></div>", unsafe_allow_html=True)
    
    is_curr = search_query and match_indices and i == match_indices[st.session_state.search_idx]
    
    # å¤´åƒé€»è¾‘ï¼šä¼˜å…ˆç”¨å›¾ç‰‡
    current_avatar = ai_avatar if msg["role"] == "assistant" else user_avatar
    # å†æ¬¡ç¡®è®¤æ–‡ä»¶å­˜åœ¨ï¼Œå¦åˆ™ç”¨ emoji
    if current_avatar != "ğŸ‘©â€ğŸ’¼" and current_avatar != "ğŸ‘¨â€ğŸ’¼" and not os.path.exists(current_avatar):
        current_avatar = "ğŸ‘©â€ğŸ’¼" if msg["role"] == "assistant" else "ğŸ‘¨â€ğŸ’¼"

    with st.chat_message(msg["role"], avatar=current_avatar):
        st.caption(f"{msg.get('timestamp','')} {'| ğŸ“' if is_curr else ''}")
        if msg.get("code_output"):
            st.markdown(f"<div class='code-output'>{msg['code_output']}</div>", unsafe_allow_html=True)
        
        content = msg["content"]
        if search_query: content = re.compile(re.escape(search_query), re.IGNORECASE).sub(lambda m: f"<mark>{m.group()}</mark>", content)
        clean = re.sub(r'```python.*?```', '', content, flags=re.DOTALL)
        if is_curr: st.markdown(f"<div class='current-match'>{clean}</div>", unsafe_allow_html=True)
        else: st.markdown(clean, unsafe_allow_html=True)
        
        if msg.get("image_path") and os.path.exists(msg["image_path"]): st.image(msg["image_path"])
        if msg.get("audio_path") and os.path.exists(msg.get("audio_path")): st.audio(msg["audio_path"], format="audio/wav")

u_in_text = st.chat_input("è¯·é—®é‡‘é‘«...")
u_in = None
if text_voice and text_voice['bytes']:
    t = transcribe_audio(text_voice['bytes'])
    if t: u_in = t
elif u_in_text: u_in = u_in_text

if u_in:
    st.session_state.messages.append({"id": str(uuid.uuid4()), "role": "user", "content": u_in, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "hidden": False})
    save_memory(st.session_state.messages)
    st.rerun()

if st.session_state.messages and st.session_state.messages[-1]["role"] == "user":
    last = st.session_state.messages[-1]
    with st.chat_message("assistant", avatar=ai_avatar if os.path.exists(ai_avatar) else "ğŸ‘©â€ğŸ’¼"):
        ph = st.empty(); img = None; out = None; txt = ""
        if st.session_state.chat_session:
            with st.spinner("â˜ï¸ äº‘ç«¯è¿ç®—ä¸­..."):
                try:
                    resp = st.session_state.chat_session.send_message(last["content"])
                    txt = resp.text
                    codes = re.findall(r'```python(.*?)```', txt, re.DOTALL)
                    if codes: img, out = execute_local_code_and_save(codes[-1])
                    if out: st.markdown(f"<div class='code-output'>{out}</div>", unsafe_allow_html=True)
                    clean = re.sub(r'```python.*?```', '', txt, flags=re.DOTALL)
                    ph.markdown(clean)
                    if img: st.image(img)
                except Exception as e: st.error(f"Error: {e}")
        af = None
        if "å¼‚å¸¸" not in (out or ""):
            try:
                spoken = get_spoken_response(txt)
                ap = os.path.join(AUDIO_DIR, f"v_{int(time.time())}.wav")
                # äº‘ç«¯è¯­éŸ³ç”Ÿæˆ
                if save_audio_cloud(spoken, ap): st.audio(ap, format="audio/wav"); af = ap
            except: pass
        st.session_state.messages.append({"id": str(uuid.uuid4()), "role": "assistant", "content": txt, "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"), "hidden": False, "image_path": img, "audio_path": af, "code_output": out})
        save_memory(st.session_state.messages)

if st.session_state.monitor_active:
    time.sleep(5)
    st.rerun()
